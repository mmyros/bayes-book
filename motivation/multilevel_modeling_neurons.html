
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Bayesian Methods for Multilevel Modeling of Neurons &#8212; Bayes Window examples</title>
    
  <link href="../_static/css/theme.css" rel="stylesheet">
  <link href="../_static/css/index.ff1ffe594081f20da1ef19478df9384b.css" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-book-theme.css?digest=c3fdc42140077d1ad13ad2f1588a4309" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.be7d3bbb2ef33a8344ce.js">

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/togglebutton.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/sphinx-book-theme.12a9622fbb08dcb3a2a40b2c02b83a57.js"></script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script async="async" src="https://unpkg.com/thebe@0.5.1/lib/index.js"></script>
    <script>
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="LFP example" href="../lfp_example/quick_lfp.html" />
    <link rel="prev" title="Multilevel modeling of LFP" href="multilevel_modeling_lfp.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../_static/logo.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Bayes Window examples</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="metropolis.html">
   Intuition for maximal likelihood or posterior inference
  </a>
 </li>
</ul>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../radon_example/radon.html">
   Radon example from Gelman and Hill (2006)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="multilevel_modeling_lfp.html">
   Multilevel modeling of LFP
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   Bayesian Methods for Multilevel Modeling of Neurons
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../lfp_example/quick_lfp.html">
   LFP example
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../lfp_example/lfp_stim_strength.html">
   LFP example with stim strength
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../lfp_example/lfp_roc.html">
   Compare to ANOVA and LMM: ROC curve
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../neurons_example/quickstart.html">
   Neurons example, pt. 1
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../neurons_example/posteriors.html">
   Neurons example, no slopes
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../neurons_example/stim_strength.html">
   Neurons example with nominal stim strengths
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../neurons_example/stim_type.html">
   Neurons example with stim types
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../neurons_example/lme.html">
   Linear mixed effects
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../neurons_example/monster.html">
   Neurons example, pt. 2: large datasets
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../neurons_example/model_comparison.html">
   Compare to alternative models
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../neurons_example/detailed_workflow.html">
   Neurons example via low-level, flexible interface
  </a>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../_sources/motivation/multilevel_modeling_neurons.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        <a class="repository-button"
            href="https://github.com/mmyros/bayes-window"><button type="button" class="btn btn-secondary topbarbtn"
                data-toggle="tooltip" data-placement="left" title="Source repository"><i
                    class="fab fa-github"></i>repository</button></a>
        <a class="issues-button"
            href="https://github.com/mmyros/bayes-window/issues/new?title=Issue%20on%20page%20%2Fmotivation/multilevel_modeling_neurons.html&body=Your%20issue%20content%20here."><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Open an issue"><i class="fas fa-lightbulb"></i>open issue</button></a>
        
    </div>
</div>

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        <a class="binder-button" href="https://mybinder.org/v2/gh/mmyros/bayes-window/master?urlpath=tree/motivation/multilevel_modeling_neurons.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Launch Binder" data-toggle="tooltip"
                data-placement="left"><img class="binder-button-logo"
                    src="../_static/images/logo_binder.svg"
                    alt="Interact on binder">Binder</button></a>
        
        
        
        
    </div>
</div>

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Contents
            </div>
            <nav id="bd-toc-nav" aria-label="Page">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#data-organization">
   Data organization
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#conventional-approaches">
   Conventional approaches
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#multilevel-and-hierarchical-models">
   Multilevel and hierarchical models
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#partial-pooling-model">
   Partial pooling model
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#varying-intercept-model">
   Varying intercept model
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#varying-intercept-and-slope-model">
   Varying intercept and slope model
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#reparametrization">
   Reparametrization
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#adding-group-level-predictors">
   Adding group-level predictors
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#correlations-among-levels">
   Correlations among levels
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#prediction">
   Prediction
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#benefits-of-multilevel-models">
   Benefits of Multilevel Models
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#references">
   References
  </a>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="tex2jax_ignore mathjax_ignore section" id="bayesian-methods-for-multilevel-modeling-of-neurons">
<h1>Bayesian Methods for Multilevel Modeling of Neurons<a class="headerlink" href="#bayesian-methods-for-multilevel-modeling-of-neurons" title="Permalink to this headline">¶</a></h1>
<p>This is a slight reworking of the radon example from pymc3 <a class="reference external" href="https://docs.pymc.io/notebooks/multilevel_modeling.html">https://docs.pymc.io/notebooks/multilevel_modeling.html</a></p>
<p>Why this notebook? It’s a common departure point to consider multilevel models in neuroscience.</p>
<p>Implementations in:</p>
<ul class="simple">
<li><p>tensorflow <a class="reference external" href="https://www.tensorflow.org/probability/examples/Multilevel_Modeling_Primer">https://www.tensorflow.org/probability/examples/Multilevel_Modeling_Primer</a></p></li>
<li><p>pymc3 <a class="reference external" href="https://docs.pymc.io/notebooks/multilevel_modeling.html">https://docs.pymc.io/notebooks/multilevel_modeling.html</a></p></li>
<li><p>stan <a class="reference external" href="https://mc-stan.org/users/documentation/case-studies/radon.html">https://mc-stan.org/users/documentation/case-studies/radon.html</a></p></li>
<li><p>pyro <a class="reference external" href="https://github.com/pyro-ppl/pyro-models/blob/master/pyro_models/arm/radon.py">https://github.com/pyro-ppl/pyro-models/blob/master/pyro_models/arm/radon.py</a></p></li>
<li><p>numpyro fibrosis dataset <a class="reference external" href="http://num.pyro.ai/en/stable/tutorials/bayesian_hierarchical_linear_regression.html">http://num.pyro.ai/en/stable/tutorials/bayesian_hierarchical_linear_regression.html</a></p></li>
</ul>
<p>Hierarchical or multilevel modeling is a generalization of regression modeling. <em>Multilevel models</em> are regression models in which the constituent model parameters are given <strong>probability models</strong>. This implies that model parameters are allowed to <strong>vary by group</strong>. Observational units are often naturally <strong>clustered</strong>. Clustering induces dependence between observations, despite random sampling of clusters and random sampling within clusters.</p>
<p>A <em>hierarchical model</em> is a particular multilevel model where parameters are nested within one another. Some multilevel structures are not hierarchical – e.g. “country” and “year” are not nested, but may represent separate, but overlapping, clusters of parameters. We will motivate this topic using a neuroscience example.</p>
<p>Example: firing rate (modified Gelman and Hill 2006)</p>
<p>Firing rate is a measure of neuronal activity. It varies greatly from neuron to neuron.</p>
<p>The EPA did a study of radon levels in firing rate in 80,000 households (more on this study and modeling here <a class="reference external" href="https://pymc3-testing.readthedocs.io/en/rtd-docs/notebooks/multilevel_modeling.html">https://pymc3-testing.readthedocs.io/en/rtd-docs/notebooks/multilevel_modeling.html</a>). We are going to call homes “neurons”, counties “mice”, and radon levels “firing rate.” The firing rate is going to vary depending on “no_stim” (originally floor condition) or “stim” (originally basement condition) that in our case denote, say, optogenetic stimulation of prefrontal cortex. There are two important predictors:</p>
<ul class="simple">
<li><p>measurement in stim or first no_stim (firingrate higher in stims)</p></li>
<li><p>mouse firing rate level (positive correlation with firingrate levels by mouse)</p></li>
</ul>
<p>The hierarchy in this example is neurons within mouse.</p>
<p>Note that we are not considering the variability that comes from house identity, which would mean neuron identity in our neuroscience language.
This means that each neuron/house has one measurement. The estimation of firing rate of a neuron is thus a separate topic.</p>
<div class="section" id="data-organization">
<h2>Data organization<a class="headerlink" href="#data-organization" title="Permalink to this headline">¶</a></h2>
<p>First, we import the data from a local file, and extract data.</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># HIDE CODE</span>

<span class="kn">import</span> <span class="nn">arviz</span> <span class="k">as</span> <span class="nn">az</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">pymc3</span> <span class="k">as</span> <span class="nn">pm</span>
<span class="kn">import</span> <span class="nn">warnings</span>
<span class="kn">from</span> <span class="nn">theano</span> <span class="kn">import</span> <span class="n">tensor</span> <span class="k">as</span> <span class="n">tt</span>

<span class="n">warnings</span><span class="o">.</span><span class="n">simplefilter</span><span class="p">(</span><span class="n">action</span><span class="o">=</span><span class="s2">&quot;ignore&quot;</span><span class="p">,</span> <span class="n">category</span><span class="o">=</span><span class="ne">FutureWarning</span><span class="p">)</span>
<span class="n">RANDOM_SEED</span> <span class="o">=</span> <span class="mi">8924</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">286</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># HIDE CODE</span>

<span class="n">az</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">use</span><span class="p">(</span><span class="s2">&quot;arviz-darkgrid&quot;</span><span class="p">)</span>
<span class="c1"># Import firingrate data</span>
<span class="n">srrs2</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">pm</span><span class="o">.</span><span class="n">get_data</span><span class="p">(</span><span class="s1">&#39;srrs2.dat&#39;</span><span class="p">))</span>
<span class="n">srrs2</span><span class="o">.</span><span class="n">columns</span> <span class="o">=</span> <span class="n">srrs2</span><span class="o">.</span><span class="n">columns</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="nb">str</span><span class="o">.</span><span class="n">strip</span><span class="p">)</span>
<span class="c1"># Select a subset of &quot;mice&quot; from Minnesota</span>
<span class="n">srrs_mn</span> <span class="o">=</span> <span class="n">srrs2</span><span class="p">[</span><span class="n">srrs2</span><span class="o">.</span><span class="n">state</span><span class="o">==</span><span class="s1">&#39;MN&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p>Next, obtain the mouse-level predictor, firing rate, by combining two variables.</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># HIDE CODE</span>

<span class="n">srrs_mn</span><span class="p">[</span><span class="s1">&#39;fips&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">srrs_mn</span><span class="o">.</span><span class="n">stfips</span><span class="o">*</span><span class="mi">1000</span> <span class="o">+</span> <span class="n">srrs_mn</span><span class="o">.</span><span class="n">cntyfips</span>
<span class="n">cty</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">pm</span><span class="o">.</span><span class="n">get_data</span><span class="p">(</span><span class="s1">&#39;cty.dat&#39;</span><span class="p">))</span>
<span class="n">cty_mn</span> <span class="o">=</span> <span class="n">cty</span><span class="p">[</span><span class="n">cty</span><span class="o">.</span><span class="n">st</span><span class="o">==</span><span class="s1">&#39;MN&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
<span class="n">cty_mn</span><span class="p">[</span> <span class="s1">&#39;fips&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1000</span><span class="o">*</span><span class="n">cty_mn</span><span class="o">.</span><span class="n">stfips</span> <span class="o">+</span> <span class="n">cty_mn</span><span class="o">.</span><span class="n">ctfips</span>
</pre></div>
</div>
</div>
</div>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># HIDE CODE</span>

<span class="nb">print</span><span class="p">(</span><span class="n">srrs_mn</span><span class="o">.</span><span class="n">columns</span><span class="p">,</span><span class="n">srrs_mn</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">cty_mn</span><span class="o">.</span><span class="n">columns</span><span class="p">,</span><span class="n">cty_mn</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Index([&#39;idnum&#39;, &#39;state&#39;, &#39;state2&#39;, &#39;stfips&#39;, &#39;zip&#39;, &#39;region&#39;, &#39;typebldg&#39;,
       &#39;floor&#39;, &#39;room&#39;, &#39;basement&#39;, &#39;windoor&#39;, &#39;rep&#39;, &#39;stratum&#39;, &#39;wave&#39;,
       &#39;starttm&#39;, &#39;stoptm&#39;, &#39;startdt&#39;, &#39;stopdt&#39;, &#39;activity&#39;, &#39;pcterr&#39;, &#39;adjwt&#39;,
       &#39;dupflag&#39;, &#39;zipflag&#39;, &#39;cntyfips&#39;, &#39;county&#39;, &#39;fips&#39;],
      dtype=&#39;object&#39;) (919, 26)
Index([&#39;stfips&#39;, &#39;ctfips&#39;, &#39;st&#39;, &#39;cty&#39;, &#39;lon&#39;, &#39;lat&#39;, &#39;Uppm&#39;, &#39;fips&#39;], dtype=&#39;object&#39;) (89, 8)
</pre></div>
</div>
</div>
</div>
<p>Use the <code class="docutils literal notranslate"><span class="pre">merge</span></code> method to combine neuron- and mouse-level information in a single DataFrame.</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># HIDE CODE</span>

<span class="n">srrs_mn</span> <span class="o">=</span> <span class="n">srrs_mn</span><span class="o">.</span><span class="n">merge</span><span class="p">(</span><span class="n">cty_mn</span><span class="p">[[</span><span class="s1">&#39;fips&#39;</span><span class="p">,</span> <span class="s1">&#39;Uppm&#39;</span><span class="p">]],</span> <span class="n">on</span><span class="o">=</span><span class="s1">&#39;fips&#39;</span><span class="p">)</span>
<span class="n">srrs_mn</span> <span class="o">=</span> <span class="n">srrs_mn</span><span class="o">.</span><span class="n">drop_duplicates</span><span class="p">(</span><span class="n">subset</span><span class="o">=</span><span class="s1">&#39;idnum&#39;</span><span class="p">)</span>
<span class="n">u</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">srrs_mn</span><span class="o">.</span><span class="n">Uppm</span><span class="p">)</span><span class="o">.</span><span class="n">unique</span><span class="p">()</span>

<span class="n">n</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">srrs_mn</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># HIDE CODE</span>

<span class="n">srrs_mn</span><span class="p">[</span><span class="s1">&#39;Uppm&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">unique</span><span class="p">()</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span><span class="n">srrs_mn</span><span class="p">[</span><span class="s1">&#39;activity&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">unique</span><span class="p">()</span><span class="o">.</span><span class="n">shape</span>
<span class="c1">#plt.scatter(srrs_mn[&#39;Uppm&#39;],srrs_mn[&#39;activity&#39;])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>((85,), (156,))
</pre></div>
</div>
</div>
</div>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># HIDE CODE</span>

<span class="c1"># Rename environmental variables to represent </span>
<span class="c1"># what we think of as a neuroscience example</span>
<span class="n">srrs_mn</span><span class="o">.</span><span class="n">rename</span><span class="p">({</span><span class="s1">&#39;floor&#39;</span><span class="p">:</span><span class="s1">&#39;no_stim&#39;</span><span class="p">,</span><span class="s1">&#39;basement&#39;</span><span class="p">:</span><span class="s1">&#39;stim&#39;</span><span class="p">,</span><span class="s1">&#39;county&#39;</span><span class="p">:</span><span class="s1">&#39;mouse&#39;</span><span class="p">,</span>
                <span class="s1">&#39;activity&#39;</span><span class="p">:</span><span class="s1">&#39;firingrate&#39;</span><span class="p">},</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># HIDE CODE</span>

<span class="n">srrs_mn</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>idnum</th>
      <th>state</th>
      <th>state2</th>
      <th>stfips</th>
      <th>zip</th>
      <th>region</th>
      <th>typebldg</th>
      <th>no_stim</th>
      <th>room</th>
      <th>stim</th>
      <th>...</th>
      <th>stopdt</th>
      <th>firingrate</th>
      <th>pcterr</th>
      <th>adjwt</th>
      <th>dupflag</th>
      <th>zipflag</th>
      <th>cntyfips</th>
      <th>mouse</th>
      <th>fips</th>
      <th>Uppm</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>5081</td>
      <td>MN</td>
      <td>MN</td>
      <td>27</td>
      <td>55735</td>
      <td>5</td>
      <td>1</td>
      <td>1</td>
      <td>3</td>
      <td>N</td>
      <td>...</td>
      <td>12288</td>
      <td>2.2</td>
      <td>9.7</td>
      <td>1146.499190</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>AITKIN</td>
      <td>27001</td>
      <td>0.502054</td>
    </tr>
    <tr>
      <th>1</th>
      <td>5082</td>
      <td>MN</td>
      <td>MN</td>
      <td>27</td>
      <td>55748</td>
      <td>5</td>
      <td>1</td>
      <td>0</td>
      <td>4</td>
      <td>Y</td>
      <td>...</td>
      <td>12088</td>
      <td>2.2</td>
      <td>14.5</td>
      <td>471.366223</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>AITKIN</td>
      <td>27001</td>
      <td>0.502054</td>
    </tr>
    <tr>
      <th>2</th>
      <td>5083</td>
      <td>MN</td>
      <td>MN</td>
      <td>27</td>
      <td>55748</td>
      <td>5</td>
      <td>1</td>
      <td>0</td>
      <td>4</td>
      <td>Y</td>
      <td>...</td>
      <td>21188</td>
      <td>2.9</td>
      <td>9.6</td>
      <td>433.316718</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>AITKIN</td>
      <td>27001</td>
      <td>0.502054</td>
    </tr>
    <tr>
      <th>3</th>
      <td>5084</td>
      <td>MN</td>
      <td>MN</td>
      <td>27</td>
      <td>56469</td>
      <td>5</td>
      <td>1</td>
      <td>0</td>
      <td>4</td>
      <td>Y</td>
      <td>...</td>
      <td>123187</td>
      <td>1.0</td>
      <td>24.3</td>
      <td>461.623670</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>AITKIN</td>
      <td>27001</td>
      <td>0.502054</td>
    </tr>
    <tr>
      <th>4</th>
      <td>5085</td>
      <td>MN</td>
      <td>MN</td>
      <td>27</td>
      <td>55011</td>
      <td>3</td>
      <td>1</td>
      <td>0</td>
      <td>4</td>
      <td>Y</td>
      <td>...</td>
      <td>13088</td>
      <td>3.1</td>
      <td>13.8</td>
      <td>433.316718</td>
      <td>0</td>
      <td>0</td>
      <td>3</td>
      <td>ANOKA</td>
      <td>27003</td>
      <td>0.428565</td>
    </tr>
  </tbody>
</table>
<p>5 rows × 27 columns</p>
</div></div></div>
</div>
<p>We also need a lookup table (<code class="docutils literal notranslate"><span class="pre">dict</span></code>) for each unique mouse, for indexing.</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># HIDE CODE</span>

<span class="n">srrs_mn</span><span class="o">.</span><span class="n">mouse</span> <span class="o">=</span> <span class="n">srrs_mn</span><span class="o">.</span><span class="n">mouse</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="nb">str</span><span class="o">.</span><span class="n">strip</span><span class="p">)</span>
<span class="n">mn_mice</span> <span class="o">=</span> <span class="n">srrs_mn</span><span class="o">.</span><span class="n">mouse</span><span class="o">.</span><span class="n">unique</span><span class="p">()</span>
<span class="n">n_mice</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">mn_mice</span><span class="p">)</span>
<span class="n">mouse_lookup</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">mn_mice</span><span class="p">,</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_mice</span><span class="p">)))</span>
</pre></div>
</div>
</div>
</div>
<p>Finally, create local copies of variables.</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># HIDE CODE</span>

<span class="n">mouse</span> <span class="o">=</span> <span class="n">srrs_mn</span><span class="p">[</span><span class="s1">&#39;mouse_code&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">srrs_mn</span><span class="o">.</span><span class="n">mouse</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="n">mouse_lookup</span><span class="p">)</span><span class="o">.</span><span class="n">values</span>
<span class="n">firingrate</span> <span class="o">=</span> <span class="n">srrs_mn</span><span class="o">.</span><span class="n">firingrate</span>
<span class="n">srrs_mn</span><span class="p">[</span><span class="s1">&#39;log_firingrate&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">log_firingrate</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">firingrate</span> <span class="o">+</span> <span class="mf">0.1</span><span class="p">)</span><span class="o">.</span><span class="n">values</span>
<span class="n">no_stim</span> <span class="o">=</span> <span class="n">srrs_mn</span><span class="o">.</span><span class="n">no_stim</span><span class="o">.</span><span class="n">values</span>
</pre></div>
</div>
</div>
</div>
<p>Distribution of firing rate levels (log scale):</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># HIDE CODE</span>

<span class="n">srrs_mn</span><span class="o">.</span><span class="n">log_firingrate</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">bins</span><span class="o">=</span><span class="mi">25</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/multilevel_modeling_neurons_21_0.png" src="../_images/multilevel_modeling_neurons_21_0.png" />
</div>
</div>
</div>
<div class="section" id="conventional-approaches">
<h2>Conventional approaches<a class="headerlink" href="#conventional-approaches" title="Permalink to this headline">¶</a></h2>
<p>The two conventional alternatives to modeling firing rate exposure represent the two extremes of the bias-variance tradeoff:</p>
<p><em><strong>Complete pooling</strong></em>:</p>
<p>Treat all mice the same, and estimate a single firing rate level.</p>
<div class="math notranslate nohighlight">
\[y_i = \alpha + \beta x_i + \epsilon_i\]</div>
<p><em><strong>No pooling</strong></em>:</p>
<p>Model firing rate in each mouse independently.</p>
<div class="math notranslate nohighlight">
\[y_i = \alpha_{j[i]} + \beta x_i + \epsilon_i\]</div>
<p>where <span class="math notranslate nohighlight">\(j = 1,\ldots,85\)</span></p>
<p>The errors <span class="math notranslate nohighlight">\(\epsilon_i\)</span> may represent measurement error, temporal within-neuron variation, or variation among neurons.</p>
<p>We’ll start by estimating the slope and intercept for the complete pooling model. You’ll notice that we used an <em>index</em> variable instead of an <em>indicator</em> variable in the linear model below. There are two main reasons. One, this generalizes well to more-than-two-category cases. Two, this approach correctly considers that neither category has more prior uncertainty than the other. On the contrary, the indicator variable approach necessarily assumes that one of the categories has more uncertainty than the other: here, the cases when <code class="docutils literal notranslate"><span class="pre">no_stim=1</span></code> would take into account 2 priors (<span class="math notranslate nohighlight">\(\alpha + \beta\)</span>), whereas cases when <code class="docutils literal notranslate"><span class="pre">no_stim=0</span></code> would have only one prior (<span class="math notranslate nohighlight">\(\alpha\)</span>). But <em>a priori</em> we aren’t more unsure about no_stim measurements than about stim measurements, so it makes sense to give them the same prior uncertainty.</p>
<p>Now for the model:</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># HIDE CODE</span>

<span class="k">with</span> <span class="n">pm</span><span class="o">.</span><span class="n">Model</span><span class="p">()</span> <span class="k">as</span> <span class="n">pooled_model</span><span class="p">:</span>
    <span class="n">a</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="s1">&#39;a&#39;</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="mf">10.</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
    
    <span class="n">theta</span> <span class="o">=</span> <span class="n">a</span><span class="p">[</span><span class="n">no_stim</span><span class="p">]</span>
    <span class="n">sigma</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Exponential</span><span class="p">(</span><span class="s1">&#39;sigma&#39;</span><span class="p">,</span> <span class="mf">1.</span><span class="p">)</span>
    
    <span class="n">y</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="s1">&#39;y&#39;</span><span class="p">,</span> <span class="n">theta</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="n">sigma</span><span class="p">,</span> <span class="n">observed</span><span class="o">=</span><span class="n">log_firingrate</span><span class="p">)</span>
    
<span class="n">pm</span><span class="o">.</span><span class="n">model_to_graphviz</span><span class="p">(</span><span class="n">pooled_model</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span><span class="gt">---------------------------------------------------------------------------</span>
<span class="ne">FileNotFoundError</span><span class="g g-Whitespace">                         </span>Traceback (most recent call last)
<span class="nn">/opt/hostedtoolcache/Python/3.7.12/x64/lib/python3.7/site-packages/graphviz/backend/execute.py</span> in <span class="ni">run_check</span><span class="nt">(cmd, input_lines, encoding, capture_output, quiet, **kwargs)</span>
<span class="g g-Whitespace">     </span><span class="mi">79</span>             <span class="k">assert</span> <span class="nb">iter</span><span class="p">(</span><span class="n">input_lines</span><span class="p">)</span> <span class="ow">is</span> <span class="n">input_lines</span>
<span class="ne">---&gt; </span><span class="mi">80</span>             <span class="n">popen</span> <span class="o">=</span> <span class="n">subprocess</span><span class="o">.</span><span class="n">Popen</span><span class="p">(</span><span class="n">cmd</span><span class="p">,</span> <span class="n">stdin</span><span class="o">=</span><span class="n">subprocess</span><span class="o">.</span><span class="n">PIPE</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
<span class="g g-Whitespace">     </span><span class="mi">81</span>             <span class="n">stdin_write</span> <span class="o">=</span> <span class="n">popen</span><span class="o">.</span><span class="n">stdin</span><span class="o">.</span><span class="n">write</span>

<span class="nn">/opt/hostedtoolcache/Python/3.7.12/x64/lib/python3.7/subprocess.py</span> in <span class="ni">__init__</span><span class="nt">(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, encoding, errors, text)</span>
<span class="g g-Whitespace">    </span><span class="mi">799</span>                                 <span class="n">errread</span><span class="p">,</span> <span class="n">errwrite</span><span class="p">,</span>
<span class="ne">--&gt; </span><span class="mi">800</span>                                 <span class="n">restore_signals</span><span class="p">,</span> <span class="n">start_new_session</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">801</span>         <span class="k">except</span><span class="p">:</span>

<span class="nn">/opt/hostedtoolcache/Python/3.7.12/x64/lib/python3.7/subprocess.py</span> in <span class="ni">_execute_child</span><span class="nt">(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, restore_signals, start_new_session)</span>
<span class="g g-Whitespace">   </span><span class="mi">1550</span>                             <span class="n">err_msg</span> <span class="o">+=</span> <span class="s1">&#39;: &#39;</span> <span class="o">+</span> <span class="nb">repr</span><span class="p">(</span><span class="n">err_filename</span><span class="p">)</span>
<span class="ne">-&gt; </span><span class="mi">1551</span>                     <span class="k">raise</span> <span class="n">child_exception_type</span><span class="p">(</span><span class="n">errno_num</span><span class="p">,</span> <span class="n">err_msg</span><span class="p">,</span> <span class="n">err_filename</span><span class="p">)</span>
<span class="g g-Whitespace">   </span><span class="mi">1552</span>                 <span class="k">raise</span> <span class="n">child_exception_type</span><span class="p">(</span><span class="n">err_msg</span><span class="p">)</span>

<span class="ne">FileNotFoundError</span>: [Errno 2] No such file or directory: PosixPath(&#39;dot&#39;): PosixPath(&#39;dot&#39;)

<span class="n">The</span> <span class="n">above</span> <span class="n">exception</span> <span class="n">was</span> <span class="n">the</span> <span class="n">direct</span> <span class="n">cause</span> <span class="n">of</span> <span class="n">the</span> <span class="n">following</span> <span class="n">exception</span><span class="p">:</span>

<span class="ne">ExecutableNotFound</span><span class="g g-Whitespace">                        </span>Traceback (most recent call last)
<span class="nn">/opt/hostedtoolcache/Python/3.7.12/x64/lib/python3.7/site-packages/IPython/core/formatters.py</span> in <span class="ni">__call__</span><span class="nt">(self, obj)</span>
<span class="g g-Whitespace">    </span><span class="mi">343</span>             <span class="n">method</span> <span class="o">=</span> <span class="n">get_real_method</span><span class="p">(</span><span class="n">obj</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">print_method</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">344</span>             <span class="k">if</span> <span class="n">method</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
<span class="ne">--&gt; </span><span class="mi">345</span>                 <span class="k">return</span> <span class="n">method</span><span class="p">()</span>
<span class="g g-Whitespace">    </span><span class="mi">346</span>             <span class="k">return</span> <span class="kc">None</span>
<span class="g g-Whitespace">    </span><span class="mi">347</span>         <span class="k">else</span><span class="p">:</span>

<span class="nn">/opt/hostedtoolcache/Python/3.7.12/x64/lib/python3.7/site-packages/graphviz/jupyter_integration.py</span> in <span class="ni">_repr_svg_</span><span class="nt">(self)</span>
<span class="g g-Whitespace">     </span><span class="mi">10</span> 
<span class="g g-Whitespace">     </span><span class="mi">11</span>     <span class="k">def</span> <span class="nf">_repr_svg_</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="ne">---&gt; </span><span class="mi">12</span>         <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">pipe</span><span class="p">(</span><span class="nb">format</span><span class="o">=</span><span class="s1">&#39;svg&#39;</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_encoding</span><span class="p">)</span>

<span class="nn">/opt/hostedtoolcache/Python/3.7.12/x64/lib/python3.7/site-packages/graphviz/piping.py</span> in <span class="ni">pipe</span><span class="nt">(self, format, renderer, formatter, quiet, engine, encoding)</span>
<span class="g g-Whitespace">    </span><span class="mi">111</span>             <span class="k">if</span> <span class="n">codecs</span><span class="o">.</span><span class="n">lookup</span><span class="p">(</span><span class="n">encoding</span><span class="p">)</span> <span class="ow">is</span> <span class="n">codecs</span><span class="o">.</span><span class="n">lookup</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_encoding</span><span class="p">):</span>
<span class="g g-Whitespace">    </span><span class="mi">112</span>                 <span class="c1"># common case: both stdin and stdout need the same encoding</span>
<span class="ne">--&gt; </span><span class="mi">113</span>                 <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_pipe_lines_string</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="n">encoding</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">114</span>             <span class="n">raw</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_pipe_lines</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="n">input_encoding</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_encoding</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">115</span>             <span class="k">return</span> <span class="n">raw</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="n">encoding</span><span class="p">)</span>

<span class="nn">/opt/hostedtoolcache/Python/3.7.12/x64/lib/python3.7/site-packages/graphviz/backend/piping.py</span> in <span class="ni">pipe_lines_string</span><span class="nt">(engine, format, input_lines, encoding, renderer, formatter, quiet)</span>
<span class="g g-Whitespace">    </span><span class="mi">195</span>     <span class="n">kwargs</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;input_lines&#39;</span><span class="p">:</span> <span class="n">input_lines</span><span class="p">,</span> <span class="s1">&#39;encoding&#39;</span><span class="p">:</span> <span class="n">encoding</span><span class="p">}</span>
<span class="g g-Whitespace">    </span><span class="mi">196</span> 
<span class="ne">--&gt; </span><span class="mi">197</span>     <span class="n">proc</span> <span class="o">=</span> <span class="n">execute</span><span class="o">.</span><span class="n">run_check</span><span class="p">(</span><span class="n">cmd</span><span class="p">,</span> <span class="n">capture_output</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">quiet</span><span class="o">=</span><span class="n">quiet</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">198</span>     <span class="k">return</span> <span class="n">proc</span><span class="o">.</span><span class="n">stdout</span>

<span class="nn">/opt/hostedtoolcache/Python/3.7.12/x64/lib/python3.7/site-packages/graphviz/backend/execute.py</span> in <span class="ni">run_check</span><span class="nt">(cmd, input_lines, encoding, capture_output, quiet, **kwargs)</span>
<span class="g g-Whitespace">     </span><span class="mi">89</span>     <span class="k">except</span> <span class="ne">OSError</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
<span class="g g-Whitespace">     </span><span class="mi">90</span>         <span class="k">if</span> <span class="n">e</span><span class="o">.</span><span class="n">errno</span> <span class="o">==</span> <span class="n">errno</span><span class="o">.</span><span class="n">ENOENT</span><span class="p">:</span>
<span class="ne">---&gt; </span><span class="mi">91</span>             <span class="k">raise</span> <span class="n">ExecutableNotFound</span><span class="p">(</span><span class="n">cmd</span><span class="p">)</span> <span class="kn">from</span> <span class="nn">e</span>
<span class="g g-Whitespace">     </span><span class="mi">92</span>         <span class="k">raise</span>
<span class="g g-Whitespace">     </span><span class="mi">93</span> 

<span class="ne">ExecutableNotFound</span>: failed to execute PosixPath(&#39;dot&#39;), make sure the Graphviz executables are on your systems&#39; PATH
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;graphviz.graphs.Digraph at 0x7f608f5c2510&gt;
</pre></div>
</div>
</div>
</div>
<p>Before running the model let’s do some prior predictive checks. Indeed, having sensible priors is not only a way to incorporate scientific knowledge into the model, it can also help and make the MCMC machinery faster – here we are dealing with a simple linear regression, so no link function comes and distorts the outcome space; but one day this will happen to you and you’ll need to think hard about your priors to help your MCMC sampler. So, better to train ourselves when it’s quite easy than having to learn when it’s very hard… There is a really neat function to do that in PyMC3:</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># HIDE CODE</span>

<span class="k">with</span> <span class="n">pooled_model</span><span class="p">:</span>
    <span class="n">prior_checks</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">sample_prior_predictive</span><span class="p">(</span><span class="n">random_seed</span><span class="o">=</span><span class="n">RANDOM_SEED</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span>
    <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> 
    <span class="p">[</span><span class="n">prior_checks</span><span class="p">[</span><span class="s2">&quot;a&quot;</span><span class="p">][:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">prior_checks</span><span class="p">[</span><span class="s2">&quot;a&quot;</span><span class="p">][:,</span> <span class="mi">1</span><span class="p">]],</span>
    <span class="s2">&quot;ok&quot;</span><span class="p">,</span>
    <span class="n">alpha</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;no_stim measurement (binary)&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="s2">&quot;stim&quot;</span><span class="p">,</span> <span class="s2">&quot;no_stim&quot;</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Mean log firingrate level&quot;</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/multilevel_modeling_neurons_26_0.png" src="../_images/multilevel_modeling_neurons_26_0.png" />
</div>
</div>
<p>I’m no expert in firingrate levels, but, before seing the data, these priors seem to allow for quite a wide range of the mean log firingrate level. But don’t worry, we can always change these priors if sampling gives us hints that they might not be appropriate – after all, priors are assumptions, not oaths; and as most assumptions, they can be tested.</p>
<p>However, we can already think of an improvement. Do you see it? Remember what we said at the beginning: firingrate levels tend to be higher in stims, so we could incorporate this prior scientific knowledge into our model by giving <span class="math notranslate nohighlight">\(a_{stim}\)</span> a higher mean than <span class="math notranslate nohighlight">\(a_{no_stim}\)</span>. Here, there are so much data that the prior should be washed out anyway, but we should keep this fact in mind – for future cases or if sampling proves more difficult than expected…</p>
<p>Speaking of sampling, let’s fire up the Bayesian machinery!</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># HIDE CODE</span>

<span class="k">with</span> <span class="n">pooled_model</span><span class="p">:</span>
    <span class="n">pooled_trace</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html">
<div>
    <style>
        /* Turns off some styling */
        progress {
            /* gets rid of default border in Firefox and Opera. */
            border: none;
            /* Needs to be in here for Safari polyfill so background images work as expected. */
            background-size: auto;
        }
        .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
            background: #F44336;
        }
    </style>
  <progress value='10000' class='' max='10000' style='width:300px; height:20px; vertical-align: middle;'></progress>
  100.00% [10000/10000 00:00<00:00 Average Loss = 1,150]
</div>
</div><div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Finished [100%]: Average Loss = 1,149.9
</pre></div>
</div>
</div>
</div>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span> 
<span class="c1"># HIDE CODE</span>

<span class="k">with</span> <span class="n">pooled_model</span><span class="p">:</span>
    <span class="n">start</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">find_MAP</span><span class="p">()</span>
    <span class="n">pooled_trace</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="mi">1000</span><span class="p">,</span> <span class="n">pm</span><span class="o">.</span><span class="n">NUTS</span><span class="p">(</span><span class="n">scaling</span><span class="o">=</span><span class="n">start</span><span class="p">),</span> <span class="n">start</span><span class="o">=</span><span class="n">start</span><span class="p">,</span> <span class="n">random_seed</span><span class="o">=</span><span class="n">RANDOM_SEED</span><span class="p">)</span>
<span class="n">az</span><span class="o">.</span><span class="n">summary</span><span class="p">(</span><span class="n">pooled_trace</span><span class="p">,</span> <span class="n">round_to</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html">
<div>
    <style>
        /* Turns off some styling */
        progress {
            /* gets rid of default border in Firefox and Opera. */
            border: none;
            /* Needs to be in here for Safari polyfill so background images work as expected. */
            background-size: auto;
        }
        .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
            background: #F44336;
        }
    </style>
  <progress value='14' class='' max='14' style='width:300px; height:20px; vertical-align: middle;'></progress>
  100.00% [14/14 00:00<00:00 logp = -1,093.8, ||grad|| = 8.8772]
</div>
</div><div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
</pre></div>
</div>
<div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span>---------------------------------------------------------------------------
KeyboardInterrupt                         Traceback (most recent call last)
/tmp/ipykernel_5233/169413810.py in &lt;module&gt;
      3 with pooled_model:
      4     start = pm.find_MAP()
----&gt; 5     pooled_trace = pm.sample(1000, pm.NUTS(scaling=start), start=start, random_seed=RANDOM_SEED)
      6 az.summary(pooled_trace, round_to=2)

/opt/hostedtoolcache/Python/3.7.12/x64/lib/python3.7/site-packages/pymc3/step_methods/hmc/nuts.py in __init__(self, vars, max_treedepth, early_max_treedepth, **kwargs)
    166         `pm.sample` to the desired number of tuning steps.
    167         &quot;&quot;&quot;
--&gt; 168         super().__init__(vars, **kwargs)
    169 
    170         self.max_treedepth = max_treedepth

/opt/hostedtoolcache/Python/3.7.12/x64/lib/python3.7/site-packages/pymc3/step_methods/hmc/base_hmc.py in __init__(self, vars, scaling, step_scale, is_cov, model, blocked, potential, dtype, Emax, target_accept, gamma, k, t0, adapt_step_size, step_rand, **theano_kwargs)
     86         vars = inputvars(vars)
     87 
---&gt; 88         super().__init__(vars, blocked=blocked, model=model, dtype=dtype, **theano_kwargs)
     89 
     90         self.adapt_step_size = adapt_step_size

/opt/hostedtoolcache/Python/3.7.12/x64/lib/python3.7/site-packages/pymc3/step_methods/arraystep.py in __init__(self, vars, model, blocked, dtype, logp_dlogp_func, **theano_kwargs)
    252 
    253         if logp_dlogp_func is None:
--&gt; 254             func = model.logp_dlogp_function(vars, dtype=dtype, **theano_kwargs)
    255         else:
    256             func = logp_dlogp_func

/opt/hostedtoolcache/Python/3.7.12/x64/lib/python3.7/site-packages/pymc3/model.py in logp_dlogp_function(self, grad_vars, tempered, **kwargs)
   1002         varnames = [var.name for var in grad_vars]
   1003         extra_vars = [var for var in self.free_RVs if var.name not in varnames]
-&gt; 1004         return ValueGradFunction(costs, grad_vars, extra_vars, **kwargs)
   1005 
   1006     @property

/opt/hostedtoolcache/Python/3.7.12/x64/lib/python3.7/site-packages/pymc3/model.py in __init__(self, costs, grad_vars, extra_vars, dtype, casting, compute_grads, **kwargs)
    697         inputs = [self._vars_joined]
    698 
--&gt; 699         self._theano_function = theano.function(inputs, outputs, givens=givens, **kwargs)
    700 
    701     def set_weights(self, values):

/opt/hostedtoolcache/Python/3.7.12/x64/lib/python3.7/site-packages/theano/compile/function/__init__.py in function(inputs, outputs, mode, updates, givens, no_default_updates, accept_inplace, name, rebuild_strict, allow_input_downcast, profile, on_unused_input)
    348             on_unused_input=on_unused_input,
    349             profile=profile,
--&gt; 350             output_keys=output_keys,
    351         )
    352     return fn

/opt/hostedtoolcache/Python/3.7.12/x64/lib/python3.7/site-packages/theano/compile/function/pfunc.py in pfunc(params, outputs, mode, updates, givens, no_default_updates, accept_inplace, name, rebuild_strict, allow_input_downcast, profile, on_unused_input, output_keys)
    530         profile=profile,
    531         on_unused_input=on_unused_input,
--&gt; 532         output_keys=output_keys,
    533     )
    534 

/opt/hostedtoolcache/Python/3.7.12/x64/lib/python3.7/site-packages/theano/compile/function/types.py in orig_function(inputs, outputs, mode, accept_inplace, name, profile, on_unused_input, output_keys)
   1979         )
   1980         with config.change_flags(compute_test_value=&quot;off&quot;):
-&gt; 1981             fn = m.create(defaults)
   1982     finally:
   1983         t2 = time.time()

/opt/hostedtoolcache/Python/3.7.12/x64/lib/python3.7/site-packages/theano/compile/function/types.py in create(self, input_storage, trustme, storage_map)
   1835         with config.change_flags(traceback__limit=config.traceback__compile_limit):
   1836             _fn, _i, _o = self.linker.make_thunk(
-&gt; 1837                 input_storage=input_storage_lists, storage_map=storage_map
   1838             )
   1839 

/opt/hostedtoolcache/Python/3.7.12/x64/lib/python3.7/site-packages/theano/link/basic.py in make_thunk(self, input_storage, output_storage, storage_map)
    267             input_storage=input_storage,
    268             output_storage=output_storage,
--&gt; 269             storage_map=storage_map,
    270         )[:3]
    271 

/opt/hostedtoolcache/Python/3.7.12/x64/lib/python3.7/site-packages/theano/link/vm.py in make_all(self, profiler, input_storage, output_storage, storage_map)
   1129                 # no_recycling here.
   1130                 thunks.append(
-&gt; 1131                     node.op.make_thunk(node, storage_map, compute_map, [], impl=impl)
   1132                 )
   1133                 linker_make_thunk_time[node] = time.time() - thunk_start

/opt/hostedtoolcache/Python/3.7.12/x64/lib/python3.7/site-packages/theano/graph/op.py in make_thunk(self, node, storage_map, compute_map, no_recycling, impl)
    632             )
    633             try:
--&gt; 634                 return self.make_c_thunk(node, storage_map, compute_map, no_recycling)
    635             except (NotImplementedError, MethodNotDefined):
    636                 # We requested the c code, so don&#39;t catch the error.

/opt/hostedtoolcache/Python/3.7.12/x64/lib/python3.7/site-packages/theano/graph/op.py in make_c_thunk(self, node, storage_map, compute_map, no_recycling)
    599                 raise NotImplementedError(&quot;float16&quot;)
    600         outputs = cl.make_thunk(
--&gt; 601             input_storage=node_input_storage, output_storage=node_output_storage
    602         )
    603         thunk, node_input_filters, node_output_filters = outputs

/opt/hostedtoolcache/Python/3.7.12/x64/lib/python3.7/site-packages/theano/link/c/basic.py in make_thunk(self, input_storage, output_storage, storage_map)
   1202         init_tasks, tasks = self.get_init_tasks()
   1203         cthunk, module, in_storage, out_storage, error_storage = self.__compile__(
-&gt; 1204             input_storage, output_storage, storage_map
   1205         )
   1206 

/opt/hostedtoolcache/Python/3.7.12/x64/lib/python3.7/site-packages/theano/link/c/basic.py in __compile__(self, input_storage, output_storage, storage_map)
   1140             input_storage,
   1141             output_storage,
-&gt; 1142             storage_map,
   1143         )
   1144         return (

/opt/hostedtoolcache/Python/3.7.12/x64/lib/python3.7/site-packages/theano/link/c/basic.py in cthunk_factory(self, error_storage, in_storage, out_storage, storage_map)
   1632             for node in self.node_order:
   1633                 node.op.prepare_node(node, storage_map, None, &quot;c&quot;)
-&gt; 1634             module = get_module_cache().module_from_key(key=key, lnk=self)
   1635 
   1636         vars = self.inputs + self.outputs + self.orphans

/opt/hostedtoolcache/Python/3.7.12/x64/lib/python3.7/site-packages/theano/link/c/cmodule.py in module_from_key(self, key, lnk)
   1189             try:
   1190                 location = dlimport_workdir(self.dirname)
-&gt; 1191                 module = lnk.compile_cmodule(location)
   1192                 name = module.__file__
   1193                 assert name.startswith(location)

/opt/hostedtoolcache/Python/3.7.12/x64/lib/python3.7/site-packages/theano/link/c/basic.py in compile_cmodule(self, location)
   1548                     lib_dirs=self.lib_dirs(),
   1549                     libs=libs,
-&gt; 1550                     preargs=preargs,
   1551                 )
   1552             except Exception as e:

/opt/hostedtoolcache/Python/3.7.12/x64/lib/python3.7/site-packages/theano/link/c/cmodule.py in compile_str(module_name, src_code, location, include_dirs, lib_dirs, libs, preargs, py_module, hide_symbols)
   2494 
   2495         try:
-&gt; 2496             p_out = output_subprocess_Popen(cmd)
   2497             compile_stderr = p_out[1].decode()
   2498         except Exception:

/opt/hostedtoolcache/Python/3.7.12/x64/lib/python3.7/site-packages/theano/utils.py in output_subprocess_Popen(command, **params)
    252     # we need to use communicate to make sure we don&#39;t deadlock around
    253     # the stdout/stderr pipe.
--&gt; 254     out = p.communicate()
    255     return out + (p.returncode,)
    256 

/opt/hostedtoolcache/Python/3.7.12/x64/lib/python3.7/subprocess.py in communicate(self, input, timeout)
    962 
    963             try:
--&gt; 964                 stdout, stderr = self._communicate(input, endtime, timeout)
    965             except KeyboardInterrupt:
    966                 # https://bugs.python.org/issue25942

/opt/hostedtoolcache/Python/3.7.12/x64/lib/python3.7/subprocess.py in _communicate(self, input, endtime, orig_timeout)
   1713                             &#39;failed to raise TimeoutExpired.&#39;)
   1714 
-&gt; 1715                     ready = selector.select(timeout)
   1716                     self._check_timeout(endtime, orig_timeout, stdout, stderr)
   1717 

/opt/hostedtoolcache/Python/3.7.12/x64/lib/python3.7/selectors.py in select(self, timeout)
    413         ready = []
    414         try:
--&gt; 415             fd_event_list = self._selector.poll(timeout)
    416         except InterruptedError:
    417             return ready

KeyboardInterrupt: 
</pre></div>
</div>
</div>
</div>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># HIDE CODE</span>

<span class="k">with</span> <span class="n">pooled_model</span><span class="p">:</span>
    <span class="n">pooled_trace</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="mi">1000</span><span class="p">,</span> <span class="n">tune</span><span class="o">=</span><span class="mi">2000</span><span class="p">,</span> <span class="n">random_seed</span><span class="o">=</span><span class="n">RANDOM_SEED</span><span class="p">)</span>
<span class="n">az</span><span class="o">.</span><span class="n">summary</span><span class="p">(</span><span class="n">pooled_trace</span><span class="p">,</span> <span class="n">round_to</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Auto-assigning NUTS sampler...
Initializing NUTS using jitter+adapt_diag...
Multiprocess sampling (4 chains in 4 jobs)
NUTS: [sigma, a]
</pre></div>
</div>
<div class="output text_html">
<div>
    <style>
        /* Turns off some styling */
        progress {
            /* gets rid of default border in Firefox and Opera. */
            border: none;
            /* Needs to be in here for Safari polyfill so background images work as expected. */
            background-size: auto;
        }
        .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
            background: #F44336;
        }
    </style>
  <progress value='12000' class='' max='12000' style='width:300px; height:20px; vertical-align: middle;'></progress>
  100.00% [12000/12000 00:03<00:00 Sampling 4 chains, 0 divergences]
</div>
</div><div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Sampling 4 chains for 2_000 tune and 1_000 draw iterations (8_000 + 4_000 draws total) took 3 seconds.
</pre></div>
</div>
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>mean</th>
      <th>sd</th>
      <th>hdi_3%</th>
      <th>hdi_97%</th>
      <th>mcse_mean</th>
      <th>mcse_sd</th>
      <th>ess_mean</th>
      <th>ess_sd</th>
      <th>ess_bulk</th>
      <th>ess_tail</th>
      <th>r_hat</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>a[0]</th>
      <td>1.36</td>
      <td>0.03</td>
      <td>1.31</td>
      <td>1.42</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>4509.37</td>
      <td>4509.37</td>
      <td>4496.12</td>
      <td>2861.20</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>a[1]</th>
      <td>0.78</td>
      <td>0.06</td>
      <td>0.65</td>
      <td>0.90</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>4696.39</td>
      <td>4688.65</td>
      <td>4666.29</td>
      <td>2308.57</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>sigma</th>
      <td>0.79</td>
      <td>0.02</td>
      <td>0.76</td>
      <td>0.83</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>4345.94</td>
      <td>4345.94</td>
      <td>4356.59</td>
      <td>2786.44</td>
      <td>1.0</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>No divergences and a sampling that only took seconds – this is the Flash of samplers! Here the chains look very good (good R hat, good effective sample size, small sd), but remember to check your chains after sampling – <code class="docutils literal notranslate"><span class="pre">az.traceplot</span></code> is usually a good start.</p>
<p>Let’s see what it means on the outcome space: did the model pick-up the negative relationship between no_stim measurements and log firingrate levels? What’s the uncertainty around its estimates? To estimate the uncertainty around the neuron firingrate levels (not the average level, but measurements that would be likely in neurons), we need to sample the likelihood <code class="docutils literal notranslate"><span class="pre">y</span></code> from the model. In another words, we need to do posterior predictive checks:</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># HIDE CODE</span>

<span class="k">with</span> <span class="n">pooled_model</span><span class="p">:</span>
    <span class="n">ppc</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">sample_posterior_predictive</span><span class="p">(</span><span class="n">pooled_trace</span><span class="p">,</span> <span class="n">random_seed</span><span class="o">=</span><span class="n">RANDOM_SEED</span><span class="p">)[</span><span class="s2">&quot;y&quot;</span><span class="p">]</span>

<span class="n">a_stim</span><span class="p">,</span> <span class="n">a_no_stim</span> <span class="o">=</span> <span class="n">pooled_trace</span><span class="p">[</span><span class="s2">&quot;a&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">firingrate_stim</span><span class="p">,</span> <span class="n">firingrate_no_stim</span> <span class="o">=</span> <span class="n">ppc</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">ppc</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span> <span class="c1"># we know that no_stim=0/1 at these columns</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html">
<div>
    <style>
        /* Turns off some styling */
        progress {
            /* gets rid of default border in Firefox and Opera. */
            border: none;
            /* Needs to be in here for Safari polyfill so background images work as expected. */
            background-size: auto;
        }
        .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
            background: #F44336;
        }
    </style>
  <progress value='4000' class='' max='4000' style='width:300px; height:20px; vertical-align: middle;'></progress>
  100.00% [4000/4000 00:14<00:00]
</div>
</div></div>
</div>
<p>We can then use these samples in our plot:</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># HIDE CODE</span>

<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">no_stim</span><span class="p">,</span> <span class="n">log_firingrate</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Observations&quot;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.4</span><span class="p">)</span>

<span class="n">az</span><span class="o">.</span><span class="n">plot_hpd</span><span class="p">(</span>
    <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> 
    <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">([</span><span class="n">firingrate_stim</span><span class="p">,</span> <span class="n">firingrate_no_stim</span><span class="p">])</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> 
    <span class="n">fill_kwargs</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;alpha&quot;</span><span class="p">:</span> <span class="mf">0.2</span><span class="p">,</span> <span class="s2">&quot;label&quot;</span><span class="p">:</span> <span class="s2">&quot;Exp. distrib. of firingrate levels&quot;</span><span class="p">}</span>
<span class="p">)</span>
<span class="n">az</span><span class="o">.</span><span class="n">plot_hpd</span><span class="p">(</span>
    <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> 
    <span class="n">pooled_trace</span><span class="p">[</span><span class="s2">&quot;a&quot;</span><span class="p">],</span> 
    <span class="n">fill_kwargs</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;alpha&quot;</span><span class="p">:</span> <span class="mf">0.5</span><span class="p">,</span> <span class="s2">&quot;label&quot;</span><span class="p">:</span> <span class="s2">&quot;Exp. mean HPD&quot;</span><span class="p">}</span>
<span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="n">a_stim</span><span class="p">,</span> <span class="n">a_no_stim</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Exp. mean&quot;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="s2">&quot;stim&quot;</span><span class="p">,</span> <span class="s2">&quot;no_stim&quot;</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;no_stim measurement (binary)&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Log firingrate level&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">ncol</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">9</span><span class="p">,</span> <span class="n">frameon</span><span class="o">=</span><span class="kc">True</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>/home/m/anaconda3/envs/tf/lib/python3.6/site-packages/arviz/data/base.py:146: UserWarning: More chains (4000) than draws (2). Passed array should have shape (chains, draws, *shape)
  UserWarning,
/home/m/anaconda3/envs/tf/lib/python3.6/site-packages/arviz/data/base.py:146: UserWarning: More chains (4000) than draws (2). Passed array should have shape (chains, draws, *shape)
  UserWarning,
</pre></div>
</div>
<img alt="../_images/multilevel_modeling_neurons_34_1.png" src="../_images/multilevel_modeling_neurons_34_1.png" />
</div>
</div>
<p>The 94% interval of the expected value is very narrow, and even narrower for stim measurements, meaning that the model is slightly more confident about these observations. The sampling distribution of individual firingrate levels is much wider. We can infer that no_stim level does account for some of the variation in firingrate levels. We can see however that the model underestimates the dispersion in firingrate levels across neurons – lots of them lie outside the light orange prediction envelope. So this model is a good start but we can’t stop there.</p>
<p>Let’s compare it to the unpooled model, where we estimate the firingrate level for each mouse:</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># HIDE CODE</span>

<span class="n">n_mice</span><span class="p">,</span><span class="n">no_stim</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span><span class="n">log_firingrate</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(85, (919,), (919,))
</pre></div>
</div>
</div>
</div>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># HIDE CODE</span>

<span class="c1"># updated version:</span>
<span class="k">with</span> <span class="n">pm</span><span class="o">.</span><span class="n">Model</span><span class="p">()</span> <span class="k">as</span> <span class="n">unpooled_model</span><span class="p">:</span>
    <span class="n">a</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="s1">&#39;a&#39;</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="mf">10.</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">n_mice</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>
    
    <span class="n">theta</span> <span class="o">=</span> <span class="n">a</span><span class="p">[</span><span class="n">mouse</span><span class="p">,</span> <span class="n">no_stim</span><span class="p">]</span>
    <span class="n">sigma</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Exponential</span><span class="p">(</span><span class="s1">&#39;sigma&#39;</span><span class="p">,</span> <span class="mf">1.</span><span class="p">)</span>
    
    <span class="n">y</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="s1">&#39;y&#39;</span><span class="p">,</span> <span class="n">theta</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="n">sigma</span><span class="p">,</span> <span class="n">observed</span><span class="o">=</span><span class="n">log_firingrate</span><span class="p">)</span>

<span class="n">pm</span><span class="o">.</span><span class="n">model_to_graphviz</span><span class="p">(</span><span class="n">unpooled_model</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/multilevel_modeling_neurons_37_0.svg" src="../_images/multilevel_modeling_neurons_37_0.svg" /></div>
</div>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># HIDE CODE</span>

<span class="k">with</span> <span class="n">unpooled_model</span><span class="p">:</span>
    <span class="n">unpooled_trace</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="mi">1000</span><span class="p">,</span> <span class="n">tune</span><span class="o">=</span><span class="mi">2000</span><span class="p">,</span> <span class="n">random_seed</span><span class="o">=</span><span class="n">RANDOM_SEED</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Auto-assigning NUTS sampler...
Initializing NUTS using jitter+adapt_diag...
Multiprocess sampling (4 chains in 4 jobs)
NUTS: [sigma, a]
</pre></div>
</div>
<div class="output text_html">
<div>
    <style>
        /* Turns off some styling */
        progress {
            /* gets rid of default border in Firefox and Opera. */
            border: none;
            /* Needs to be in here for Safari polyfill so background images work as expected. */
            background-size: auto;
        }
        .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
            background: #F44336;
        }
    </style>
  <progress value='12000' class='' max='12000' style='width:300px; height:20px; vertical-align: middle;'></progress>
  100.00% [12000/12000 00:08<00:00 Sampling 4 chains, 0 divergences]
</div>
</div><div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Sampling 4 chains for 2_000 tune and 1_000 draw iterations (8_000 + 4_000 draws total) took 8 seconds.
</pre></div>
</div>
</div>
</div>
<p>Sampling went fine again. Let’s look at the expected values for both stim (dimension 0) and no_stim (dimension 1) in each mouse:</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># HIDE CODE</span>

<span class="n">az</span><span class="o">.</span><span class="n">plot_forest</span><span class="p">(</span><span class="n">unpooled_trace</span><span class="p">,</span> <span class="n">var_names</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;a&#39;</span><span class="p">],</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">32</span><span class="p">),</span> <span class="n">r_hat</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">combined</span><span class="o">=</span><span class="kc">True</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/multilevel_modeling_neurons_40_0.png" src="../_images/multilevel_modeling_neurons_40_0.png" />
</div>
</div>
<p>Sampling was good for all mice, but you can see that some are more uncertain than others, and all of these uncertain estimates are for no_stim measurements. This probably comes from the fact that some mice just have a handful of no_stim measurements, so the model is pretty uncertain about them.</p>
<p>To identify mice with high firing rate levels, we can plot the ordered mean estimates, as well as their 94% HPD:</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># HIDE CODE</span>

<span class="n">a_stim_unpooled</span><span class="p">,</span> <span class="n">a_no_stim_unpooled</span> <span class="o">=</span> <span class="n">unpooled_trace</span><span class="p">[</span><span class="s2">&quot;a&quot;</span><span class="p">][:,</span> <span class="p">:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">unpooled_trace</span><span class="p">[</span><span class="s2">&quot;a&quot;</span><span class="p">][:,</span> <span class="p">:,</span> <span class="mi">1</span><span class="p">]</span>
<span class="n">unpooled_stim</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="o">.</span><span class="n">from_dict</span><span class="p">(</span>
                        <span class="p">{</span>
                            <span class="s2">&quot;stim&quot;</span><span class="p">:</span> <span class="n">a_stim_unpooled</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> 
                            <span class="s2">&quot;low&quot;</span><span class="p">:</span> <span class="n">az</span><span class="o">.</span><span class="n">hpd</span><span class="p">(</span><span class="n">a_stim_unpooled</span><span class="p">)[:,</span> <span class="mi">0</span><span class="p">],</span> 
                            <span class="s2">&quot;high&quot;</span><span class="p">:</span> <span class="n">az</span><span class="o">.</span><span class="n">hpd</span><span class="p">(</span><span class="n">a_stim_unpooled</span><span class="p">)[:,</span> <span class="mi">1</span><span class="p">]</span>
                        <span class="p">},</span> 
                        <span class="n">orient</span><span class="o">=</span><span class="s2">&quot;index&quot;</span><span class="p">,</span> 
                        <span class="n">columns</span><span class="o">=</span><span class="n">mn_mice</span>
                    <span class="p">)</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="n">by</span><span class="o">=</span><span class="s2">&quot;stim&quot;</span><span class="p">)</span>
<span class="n">unpooled_no_stim</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="o">.</span><span class="n">from_dict</span><span class="p">(</span>
                    <span class="p">{</span>
                        <span class="s2">&quot;no_stim&quot;</span><span class="p">:</span> <span class="n">a_no_stim_unpooled</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span>
                        <span class="s2">&quot;low&quot;</span><span class="p">:</span> <span class="n">az</span><span class="o">.</span><span class="n">hpd</span><span class="p">(</span><span class="n">a_no_stim_unpooled</span><span class="p">)[:,</span> <span class="mi">0</span><span class="p">],</span> 
                        <span class="s2">&quot;high&quot;</span><span class="p">:</span> <span class="n">az</span><span class="o">.</span><span class="n">hpd</span><span class="p">(</span><span class="n">a_no_stim_unpooled</span><span class="p">)[:,</span> <span class="mi">1</span><span class="p">]</span>
                    <span class="p">},</span> 
                    <span class="n">orient</span><span class="o">=</span><span class="s2">&quot;index&quot;</span><span class="p">,</span> 
                    <span class="n">columns</span><span class="o">=</span><span class="n">mn_mice</span>
                <span class="p">)</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="n">by</span><span class="o">=</span><span class="s2">&quot;no_stim&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>/home/m/anaconda3/envs/tf/lib/python3.6/site-packages/arviz/stats/stats.py:338: UserWarning: hpd will be deprecated Please replace hdi
  warnings.warn((&quot;hpd will be deprecated &quot; &quot;Please replace hdi&quot;),)
/home/m/anaconda3/envs/tf/lib/python3.6/site-packages/arviz/data/base.py:146: UserWarning: More chains (4000) than draws (85). Passed array should have shape (chains, draws, *shape)
  UserWarning,
</pre></div>
</div>
</div>
</div>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># HIDE CODE</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
<span class="k">for</span> <span class="n">ax</span><span class="p">,</span> <span class="n">estimates</span><span class="p">,</span> <span class="n">level</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">axes</span><span class="p">,</span> <span class="p">[</span><span class="n">unpooled_stim</span><span class="p">,</span> <span class="n">unpooled_no_stim</span><span class="p">],</span> <span class="p">[</span><span class="s2">&quot;stim&quot;</span><span class="p">,</span> <span class="s2">&quot;no_stim&quot;</span><span class="p">]):</span>    
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">l</span><span class="p">,</span> <span class="n">h</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">n_mice</span><span class="p">),</span> <span class="n">estimates</span><span class="o">.</span><span class="n">low</span><span class="o">.</span><span class="n">values</span><span class="p">,</span> <span class="n">estimates</span><span class="o">.</span><span class="n">high</span><span class="o">.</span><span class="n">values</span><span class="p">):</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="n">i</span><span class="p">,</span> <span class="n">i</span><span class="p">],</span> <span class="p">[</span><span class="n">l</span><span class="p">,</span> <span class="n">h</span><span class="p">],</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.6</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s1">&#39;orange&#39;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">n_mice</span><span class="p">),</span> <span class="n">estimates</span><span class="p">[</span><span class="n">level</span><span class="p">],</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.8</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">title</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">level</span><span class="o">.</span><span class="n">title</span><span class="p">()</span><span class="si">}</span><span class="s2"> estimates&quot;</span><span class="p">,</span> <span class="n">xlabel</span><span class="o">=</span><span class="s2">&quot;Ordered mouse&quot;</span><span class="p">,</span> <span class="n">xlim</span><span class="o">=</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">86</span><span class="p">),</span> <span class="n">ylabel</span><span class="o">=</span><span class="s2">&quot;firingrate estimate&quot;</span><span class="p">,</span> <span class="n">ylim</span><span class="o">=</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="mf">4.5</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">();</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/multilevel_modeling_neurons_43_0.png" src="../_images/multilevel_modeling_neurons_43_0.png" />
</div>
</div>
<p>There seems to be more dispersion in firingrate levels for no_stim measurements than for stim ones. Moreover, as we saw in the forest plot, no_stim estimates are globally more uncertain, especially in some mice. We speculated that this is due to smaller sample sizes in the data, but let’s verify it!</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># HIDE CODE</span>

<span class="n">n_no_stim_meas</span> <span class="o">=</span> <span class="n">srrs_mn</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="s2">&quot;mouse&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">no_stim</span>
<span class="n">uncertainty</span> <span class="o">=</span> <span class="p">(</span><span class="n">unpooled_no_stim</span><span class="o">.</span><span class="n">high</span> <span class="o">-</span> <span class="n">unpooled_no_stim</span><span class="o">.</span><span class="n">low</span><span class="p">)</span><span class="o">.</span><span class="n">sort_index</span><span class="p">()</span> <span class="c1"># sort index to match counties alphabetically</span>

<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">n_no_stim_meas</span><span class="p">,</span> <span class="n">uncertainty</span><span class="p">,</span> <span class="s1">&#39;o&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">.4</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Nbr no_stim measurements in mouse&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Estimates&#39; uncertainty&quot;</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/multilevel_modeling_neurons_45_0.png" src="../_images/multilevel_modeling_neurons_45_0.png" />
</div>
</div>
<p>Bingo! This makes sense: it’s very hard to estimate no_stim firingrate levels in mice where there are no no_stim measurements, and the model is telling us that by being very uncertain in its estimates for those mice. This is a classic issue with no-pooling models: when you estimate clusters independently from each other, what do you with small-sample-size mice?</p>
<p>Another way to see this phenomenon is to visually compare the pooled and unpooled estimates for a subset of mice representing a range of sample sizes:</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># HIDE CODE</span>

<span class="c1"># These mice were named as counties in Minnesota, how curious</span>
<span class="n">SAMPLE_mice</span> <span class="o">=</span> <span class="p">(</span><span class="s1">&#39;LAC QUI PARLE&#39;</span><span class="p">,</span> <span class="s1">&#39;AITKIN&#39;</span><span class="p">,</span> <span class="s1">&#39;KOOCHICHING&#39;</span><span class="p">,</span> 
                    <span class="s1">&#39;DOUGLAS&#39;</span><span class="p">,</span> <span class="s1">&#39;CLAY&#39;</span><span class="p">,</span> <span class="s1">&#39;STEARNS&#39;</span><span class="p">,</span> <span class="s1">&#39;RAMSEY&#39;</span><span class="p">,</span> <span class="s1">&#39;ST LOUIS&#39;</span><span class="p">)</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">6</span><span class="p">),</span> <span class="n">sharey</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">sharex</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">axes</span> <span class="o">=</span> <span class="n">axes</span><span class="o">.</span><span class="n">ravel</span><span class="p">()</span> 
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">c</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">SAMPLE_mice</span><span class="p">):</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">srrs_mn</span><span class="o">.</span><span class="n">no_stim</span><span class="p">[</span><span class="n">srrs_mn</span><span class="o">.</span><span class="n">mouse</span><span class="o">==</span><span class="n">c</span><span class="p">]</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">srrs_mn</span><span class="o">.</span><span class="n">log_firingrate</span><span class="p">[</span><span class="n">srrs_mn</span><span class="o">.</span><span class="n">mouse</span><span class="o">==</span><span class="n">c</span><span class="p">]</span>
    
    <span class="c1"># plot obs:</span>
    <span class="n">axes</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">x</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">))</span><span class="o">*</span><span class="mf">0.01</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.4</span><span class="p">)</span>
    
    <span class="c1"># plot both models:</span>
    <span class="n">axes</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="n">unpooled_stim</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">c</span><span class="p">,</span> <span class="s2">&quot;stim&quot;</span><span class="p">]</span> <span class="p">,</span> <span class="n">unpooled_no_stim</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">c</span><span class="p">,</span> <span class="s2">&quot;no_stim&quot;</span><span class="p">]])</span>
    <span class="n">axes</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="n">a_stim</span><span class="p">,</span> <span class="n">a_no_stim</span><span class="p">],</span> <span class="s2">&quot;r--&quot;</span><span class="p">)</span>
    
    <span class="n">axes</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">set_xticks</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">])</span>
    <span class="n">axes</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">set_xticklabels</span><span class="p">([</span><span class="s2">&quot;stim&quot;</span><span class="p">,</span> <span class="s2">&quot;no_stim&quot;</span><span class="p">])</span>
    <span class="n">axes</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="n">c</span><span class="p">)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">i</span><span class="o">%</span><span class="k">2</span>:
        <span class="n">axes</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;Log firingrate level&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">();</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/multilevel_modeling_neurons_47_0.png" src="../_images/multilevel_modeling_neurons_47_0.png" />
</div>
</div>
<p>Neither of these models are satisfactory:</p>
<ul class="simple">
<li><p>If we are trying to identify high-firingrate mice, pooling is useless – because, by definition, the pooled model estimates firingrate at the cohort-level. In other words, pooling leads to maximal <em>underfitting</em>: the variation across mice is not taken into account and only the overall population is estimated.</p></li>
<li><p>We do not trust extreme unpooled estimates produced by models using few observations. This leads to maximal <em>overfitting</em>: only the within-mouse variations are taken into account and the overall population (i.e the cohort-level, which tells us about similarites across mice) is not estimated.</p></li>
</ul>
<p>This issue is acute for small sample sizes, as seen above: in mice where we have few no_stim measurements, if firingrate levels are higher for those data points than for stim ones (Aitkin, Koochiching, Ramsey), the model will estimate that firingrate levels are higher in no_stims than stims for these mice. But we shouldn’t trust this conclusion, because both scientific knowledge and the situation in other mice tell us that it is usually the reverse (stim firingrate &gt; no_stim firingrate). So unless we have a lot of observations telling us otherwise for a given mouse, we should be skeptical and shrink our mouse-estimates to the cohort-estimates – in other words, we should balance between cluster-level and population-level information, and the amount of shrinkage will depend on how extreme and how numerous the data in each cluster are.</p>
<p>But how do we do that? Well, ladies and gentlemen, let me introduce you to… hierarchical models!</p>
</div>
<div class="section" id="multilevel-and-hierarchical-models">
<h2>Multilevel and hierarchical models<a class="headerlink" href="#multilevel-and-hierarchical-models" title="Permalink to this headline">¶</a></h2>
<p>When we pool our data, we imply that they are sampled from the same model. This ignores any variation among sampling units (other than sampling variance) – we assume that mice are all the same:</p>
<p><img alt="pooled" src="http://f.cl.ly/items/0R1W063h1h0W2M2C0S3M/Screen%20Shot%202013-10-10%20at%208.22.21%20AM.png" /></p>
<p>When we analyze data unpooled, we imply that they are sampled independently from separate models. At the opposite extreme from the pooled case, this approach claims that differences between sampling units are too large to combine them – we assume that mice have no similarity whatsoever:</p>
<p><img alt="unpooled" src="http://f.cl.ly/items/38020n2t2Y2b1p3t0B0e/Screen%20Shot%202013-10-10%20at%208.23.36%20AM.png" /></p>
<p>In a hierarchical model, parameters are viewed as a sample from a population distribution of parameters. Thus, we view them as being neither entirely different or exactly the same. This is <em><strong>partial pooling</strong></em>:</p>
<p><img alt="hierarchical" src="http://f.cl.ly/items/1B3U223i002y3V2W3r0W/Screen%20Shot%202013-10-10%20at%208.25.05%20AM.png" /></p>
<p>We can use PyMC to easily specify multilevel models, and fit them using Markov chain Monte Carlo.</p>
</div>
<div class="section" id="partial-pooling-model">
<h2>Partial pooling model<a class="headerlink" href="#partial-pooling-model" title="Permalink to this headline">¶</a></h2>
<p>The simplest partial pooling model for the neuron firingrate dataset is one which simply estimates firingrate levels, without any predictors at any level. A partial pooling model represents a compromise between the pooled and unpooled extremes, approximately a weighted average (based on sample size) of the unpooled mouse estimates and the pooled estimates.</p>
<div class="math notranslate nohighlight">
\[\hat{\alpha} \approx \frac{(n_j/\sigma_y^2)\bar{y}_j + (1/\sigma_{\alpha}^2)\bar{y}}{(n_j/\sigma_y^2) + (1/\sigma_{\alpha}^2)}\]</div>
<p>Estimates for mice with smaller sample sizes will shrink towards the cohort-wide average.</p>
<p>Estimates for mice with larger sample sizes will be closer to the unpooled mouse estimates and will influence the the cohort-wide average.</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># HIDE CODE</span>

<span class="k">with</span> <span class="n">pm</span><span class="o">.</span><span class="n">Model</span><span class="p">()</span> <span class="k">as</span> <span class="n">partial_pooling</span><span class="p">:</span>
    <span class="c1"># Hyperpriors:</span>
    <span class="n">a</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="s1">&#39;a&#39;</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="mf">0.</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="mf">10.</span><span class="p">)</span>
    <span class="n">sigma_a</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Exponential</span><span class="p">(</span><span class="s1">&#39;sigma_a&#39;</span><span class="p">,</span> <span class="mf">1.</span><span class="p">)</span>
    
    <span class="c1"># Varying intercepts:</span>
    <span class="n">a_mouse</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="s1">&#39;a_mouse&#39;</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="n">a</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="n">sigma_a</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="n">n_mice</span><span class="p">)</span>
    
    <span class="c1"># Expected value per mouse:</span>
    <span class="n">theta</span> <span class="o">=</span> <span class="n">a_mouse</span><span class="p">[</span><span class="n">mouse</span><span class="p">]</span>
    <span class="c1"># Model error:</span>
    <span class="n">sigma</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Exponential</span><span class="p">(</span><span class="s1">&#39;sigma&#39;</span><span class="p">,</span> <span class="mf">1.</span><span class="p">)</span>
    
    <span class="n">y</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="s1">&#39;y&#39;</span><span class="p">,</span> <span class="n">theta</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="n">sigma</span><span class="p">,</span> <span class="n">observed</span><span class="o">=</span><span class="n">log_firingrate</span><span class="p">)</span>
<span class="n">pm</span><span class="o">.</span><span class="n">model_to_graphviz</span><span class="p">(</span><span class="n">partial_pooling</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/multilevel_modeling_neurons_51_0.svg" src="../_images/multilevel_modeling_neurons_51_0.svg" /></div>
</div>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># HIDE CODE</span>

<span class="k">with</span> <span class="n">partial_pooling</span><span class="p">:</span>
    <span class="n">partial_pooling_trace</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="mi">1000</span><span class="p">,</span> <span class="n">tune</span><span class="o">=</span><span class="mi">2000</span><span class="p">,</span> <span class="n">random_seed</span><span class="o">=</span><span class="n">RANDOM_SEED</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Auto-assigning NUTS sampler...
Initializing NUTS using jitter+adapt_diag...
Multiprocess sampling (4 chains in 4 jobs)
NUTS: [sigma, a_mouse, sigma_a, a]
</pre></div>
</div>
<div class="output text_html">
<div>
    <style>
        /* Turns off some styling */
        progress {
            /* gets rid of default border in Firefox and Opera. */
            border: none;
            /* Needs to be in here for Safari polyfill so background images work as expected. */
            background-size: auto;
        }
        .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
            background: #F44336;
        }
    </style>
  <progress value='12000' class='' max='12000' style='width:300px; height:20px; vertical-align: middle;'></progress>
  100.00% [12000/12000 00:06<00:00 Sampling 4 chains, 0 divergences]
</div>
</div><div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Sampling 4 chains for 2_000 tune and 1_000 draw iterations (8_000 + 4_000 draws total) took 6 seconds.
The number of effective samples is smaller than 25% for some parameters.
</pre></div>
</div>
</div>
</div>
<p>To compare partial-pooling and no-pooling estimates, let’s run the unpooled model without the <code class="docutils literal notranslate"><span class="pre">no_stim</span></code> predictor:</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># HIDE CODE</span>

<span class="k">with</span> <span class="n">pm</span><span class="o">.</span><span class="n">Model</span><span class="p">()</span> <span class="k">as</span> <span class="n">unpooled_bis</span><span class="p">:</span>
    <span class="n">a_mouse</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="s1">&#39;a_mouse&#39;</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="mf">10.</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="n">n_mice</span><span class="p">)</span>
    
    <span class="n">theta</span> <span class="o">=</span> <span class="n">a_mouse</span><span class="p">[</span><span class="n">mouse</span><span class="p">]</span>
    <span class="n">sigma</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Exponential</span><span class="p">(</span><span class="s1">&#39;sigma&#39;</span><span class="p">,</span> <span class="mf">1.</span><span class="p">)</span>
    
    <span class="n">y</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="s1">&#39;y&#39;</span><span class="p">,</span> <span class="n">theta</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="n">sigma</span><span class="p">,</span> <span class="n">observed</span><span class="o">=</span><span class="n">log_firingrate</span><span class="p">)</span>
    
    <span class="n">unpooled_trace_bis</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="mi">1000</span><span class="p">,</span> <span class="n">tune</span><span class="o">=</span><span class="mi">2000</span><span class="p">,</span> <span class="n">random_seed</span><span class="o">=</span><span class="n">RANDOM_SEED</span><span class="p">)</span>
<span class="n">pm</span><span class="o">.</span><span class="n">model_to_graphviz</span><span class="p">(</span><span class="n">unpooled_bis</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Auto-assigning NUTS sampler...
Initializing NUTS using jitter+adapt_diag...
Multiprocess sampling (4 chains in 4 jobs)
NUTS: [sigma, a_mouse]
</pre></div>
</div>
<div class="output text_html">
<div>
    <style>
        /* Turns off some styling */
        progress {
            /* gets rid of default border in Firefox and Opera. */
            border: none;
            /* Needs to be in here for Safari polyfill so background images work as expected. */
            background-size: auto;
        }
        .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
            background: #F44336;
        }
    </style>
  <progress value='12000' class='' max='12000' style='width:300px; height:20px; vertical-align: middle;'></progress>
  100.00% [12000/12000 00:06<00:00 Sampling 4 chains, 0 divergences]
</div>
</div><div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Sampling 4 chains for 2_000 tune and 1_000 draw iterations (8_000 + 4_000 draws total) took 7 seconds.
</pre></div>
</div>
<img alt="../_images/multilevel_modeling_neurons_54_3.svg" src="../_images/multilevel_modeling_neurons_54_3.svg" /></div>
</div>
<p>Now let’s compare both models’ estimates for all 85 mice. We’ll plot the estimates against each mouse’s sample size, to let you see more clearly what hierarchical models bring to the table:</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># HIDE CODE</span>

<span class="n">N_mouse</span> <span class="o">=</span> <span class="n">srrs_mn</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="s2">&quot;mouse&quot;</span><span class="p">)[</span><span class="s2">&quot;idnum&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">count</span><span class="p">()</span><span class="o">.</span><span class="n">values</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">4</span><span class="p">),</span> <span class="n">sharex</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">sharey</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="k">for</span> <span class="n">ax</span><span class="p">,</span> <span class="n">trace</span><span class="p">,</span> <span class="n">level</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span>
    <span class="n">axes</span><span class="p">,</span> 
    <span class="p">[</span><span class="n">unpooled_trace_bis</span><span class="p">[</span><span class="s2">&quot;a_mouse&quot;</span><span class="p">],</span> <span class="n">partial_pooling_trace</span><span class="p">[</span><span class="s2">&quot;a_mouse&quot;</span><span class="p">]],</span> 
    <span class="p">[</span><span class="s2">&quot;no pooling&quot;</span><span class="p">,</span> <span class="s2">&quot;partial pooling&quot;</span><span class="p">]</span>
<span class="p">):</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">hlines</span><span class="p">(</span>
        <span class="n">partial_pooling_trace</span><span class="p">[</span><span class="s2">&quot;a&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">(),</span> 
        <span class="mf">0.9</span><span class="p">,</span> 
        <span class="nb">max</span><span class="p">(</span><span class="n">N_mouse</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> 
        <span class="n">alpha</span><span class="o">=</span><span class="mf">0.4</span><span class="p">,</span> 
        <span class="n">ls</span><span class="o">=</span><span class="s2">&quot;--&quot;</span><span class="p">,</span> 
        <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Est. population mean&quot;</span>
    <span class="p">)</span>
    <span class="k">for</span> <span class="n">n</span><span class="p">,</span> <span class="n">l</span><span class="p">,</span> <span class="n">h</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span>
        <span class="n">N_mouse</span><span class="p">,</span> 
        <span class="n">az</span><span class="o">.</span><span class="n">hpd</span><span class="p">(</span><span class="n">trace</span><span class="p">)[:,</span> <span class="mi">0</span><span class="p">],</span> 
        <span class="n">az</span><span class="o">.</span><span class="n">hpd</span><span class="p">(</span><span class="n">trace</span><span class="p">)[:,</span> <span class="mi">1</span><span class="p">]</span>
    <span class="p">):</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="n">n</span><span class="p">,</span> <span class="n">n</span><span class="p">],</span> <span class="p">[</span><span class="n">l</span><span class="p">,</span> <span class="n">h</span><span class="p">],</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s2">&quot;orange&quot;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">N_mouse</span><span class="p">,</span> <span class="n">trace</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.8</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set</span><span class="p">(</span>
        <span class="n">title</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">level</span><span class="o">.</span><span class="n">title</span><span class="p">()</span><span class="si">}</span><span class="s2"> Estimates&quot;</span><span class="p">,</span> 
        <span class="n">xlabel</span><span class="o">=</span><span class="s2">&quot;Nbr obs in mouse (log scale)&quot;</span><span class="p">,</span> 
        <span class="n">xscale</span><span class="o">=</span><span class="s2">&quot;log&quot;</span><span class="p">,</span> 
        <span class="n">ylabel</span><span class="o">=</span><span class="s2">&quot;Log firingrate&quot;</span>
    <span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">fontsize</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">();</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>/home/m/anaconda3/envs/tf/lib/python3.6/site-packages/arviz/stats/stats.py:338: UserWarning: hpd will be deprecated Please replace hdi
  warnings.warn((&quot;hpd will be deprecated &quot; &quot;Please replace hdi&quot;),)
/home/m/anaconda3/envs/tf/lib/python3.6/site-packages/arviz/data/base.py:146: UserWarning: More chains (4000) than draws (85). Passed array should have shape (chains, draws, *shape)
  UserWarning,
</pre></div>
</div>
<img alt="../_images/multilevel_modeling_neurons_56_1.png" src="../_images/multilevel_modeling_neurons_56_1.png" />
</div>
</div>
<p>Notice the difference between the unpooled and partially-pooled estimates, particularly at smaller sample sizes: As expected, the former are both more extreme and more imprecise. Indeed, in the partially-pooled model, estimates in small-sample-size mice are informed by the population parameters – hence more precise estimates. Moreover, the smaller the sample size, the more regression towards the overall mean (the dashed gray line) – hence less extreme estimates. In other words, the model is skeptical of extreme deviations from the population mean in mice where data is sparse.</p>
<p>Now let’s try to integrate the <code class="docutils literal notranslate"><span class="pre">no_stim</span></code> predictor! To show you an example with a slope we’re gonna take the indicator variable road, but we could stay with the index variable approach that we used for the no-pooling model. Then we would have one intercept for each category – stim and no_stim.</p>
</div>
<div class="section" id="varying-intercept-model">
<h2>Varying intercept model<a class="headerlink" href="#varying-intercept-model" title="Permalink to this headline">¶</a></h2>
<p>As above, this model allows intercepts to vary across mouse, according to a random effect. We just add a fixed slope for the predictor (i.e all mice will have the same slope):</p>
<div class="math notranslate nohighlight">
\[y_i = \alpha_{j[i]} + \beta x_{i} + \epsilon_i\]</div>
<p>where</p>
<div class="math notranslate nohighlight">
\[\epsilon_i \sim N(0, \sigma_y^2)\]</div>
<p>and the intercept random effect:</p>
<div class="math notranslate nohighlight">
\[\alpha_{j[i]} \sim N(\mu_{\alpha}, \sigma_{\alpha}^2)\]</div>
<p>As with the the no-pooling model, we set a separate intercept for each mouse, but rather than fitting separate regression models for each mouse, multilevel modeling <strong>shares strength</strong> among mice, allowing for more reasonable inference in mice with little data. Here is what that looks in code:</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># HIDE CODE</span>

<span class="k">with</span> <span class="n">pm</span><span class="o">.</span><span class="n">Model</span><span class="p">()</span> <span class="k">as</span> <span class="n">varying_intercept</span><span class="p">:</span>
    <span class="c1"># Hyperpriors:</span>
    <span class="n">a</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="s1">&#39;a&#39;</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="mf">0.</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="mf">10.</span><span class="p">)</span>
    <span class="n">sigma_a</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Exponential</span><span class="p">(</span><span class="s1">&#39;sigma_a&#39;</span><span class="p">,</span> <span class="mf">1.</span><span class="p">)</span>
    
    <span class="c1"># Varying intercepts:</span>
    <span class="n">a_mouse</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="s1">&#39;a_mouse&#39;</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="n">a</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="n">sigma_a</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="n">n_mice</span><span class="p">)</span>
    <span class="c1"># Common slope:</span>
    <span class="n">b</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="s1">&#39;b&#39;</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="mf">0.</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="mf">10.</span><span class="p">)</span>
    
    <span class="c1"># Expected value per mouse:</span>
    <span class="n">theta</span> <span class="o">=</span> <span class="n">a_mouse</span><span class="p">[</span><span class="n">mouse</span><span class="p">]</span> <span class="o">+</span> <span class="n">b</span> <span class="o">*</span> <span class="n">no_stim</span>
    <span class="c1"># Model error:</span>
    <span class="n">sigma</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Exponential</span><span class="p">(</span><span class="s1">&#39;sigma&#39;</span><span class="p">,</span> <span class="mf">1.</span><span class="p">)</span>
    
    <span class="n">y</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="s1">&#39;y&#39;</span><span class="p">,</span> <span class="n">theta</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="n">sigma</span><span class="p">,</span> <span class="n">observed</span><span class="o">=</span><span class="n">log_firingrate</span><span class="p">)</span>
<span class="n">pm</span><span class="o">.</span><span class="n">model_to_graphviz</span><span class="p">(</span><span class="n">varying_intercept</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/multilevel_modeling_neurons_59_0.svg" src="../_images/multilevel_modeling_neurons_59_0.svg" /></div>
</div>
<p>Let’s fit this bad boy with MCMC:</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># HIDE CODE</span>

<span class="k">with</span> <span class="n">varying_intercept</span><span class="p">:</span>
    <span class="n">varying_intercept_trace</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="mi">1000</span><span class="p">,</span> <span class="n">tune</span><span class="o">=</span><span class="mi">2000</span><span class="p">,</span> <span class="n">random_seed</span><span class="o">=</span><span class="n">RANDOM_SEED</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Auto-assigning NUTS sampler...
Initializing NUTS using jitter+adapt_diag...
Multiprocess sampling (4 chains in 4 jobs)
NUTS: [sigma, b, a_mouse, sigma_a, a]
</pre></div>
</div>
<div class="output text_html">
<div>
    <style>
        /* Turns off some styling */
        progress {
            /* gets rid of default border in Firefox and Opera. */
            border: none;
            /* Needs to be in here for Safari polyfill so background images work as expected. */
            background-size: auto;
        }
        .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
            background: #F44336;
        }
    </style>
  <progress value='12000' class='' max='12000' style='width:300px; height:20px; vertical-align: middle;'></progress>
  100.00% [12000/12000 00:05<00:00 Sampling 4 chains, 0 divergences]
</div>
</div><div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Sampling 4 chains for 2_000 tune and 1_000 draw iterations (8_000 + 4_000 draws total) took 6 seconds.
</pre></div>
</div>
</div>
</div>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># HIDE CODE</span>

<span class="n">az</span><span class="o">.</span><span class="n">plot_forest</span><span class="p">(</span><span class="n">varying_intercept_trace</span><span class="p">,</span> <span class="n">var_names</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;a&quot;</span><span class="p">,</span> <span class="s2">&quot;a_mouse&quot;</span><span class="p">],</span> <span class="n">r_hat</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">combined</span><span class="o">=</span><span class="kc">True</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/multilevel_modeling_neurons_62_0.png" src="../_images/multilevel_modeling_neurons_62_0.png" />
</div>
</div>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># HIDE CODE</span>

<span class="n">az</span><span class="o">.</span><span class="n">plot_trace</span><span class="p">(</span><span class="n">varying_intercept_trace</span><span class="p">,</span> <span class="n">var_names</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;sigma_a&quot;</span><span class="p">,</span> <span class="s2">&quot;b&quot;</span><span class="p">]);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/multilevel_modeling_neurons_63_0.png" src="../_images/multilevel_modeling_neurons_63_0.png" />
</div>
</div>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># HIDE CODE</span>

<span class="n">az</span><span class="o">.</span><span class="n">summary</span><span class="p">(</span><span class="n">varying_intercept_trace</span><span class="p">,</span> <span class="n">var_names</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;a&quot;</span><span class="p">,</span> <span class="s2">&quot;sigma_a&quot;</span><span class="p">,</span> <span class="s2">&quot;b&quot;</span><span class="p">,</span> <span class="s2">&quot;sigma&quot;</span><span class="p">],</span> <span class="n">round_to</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>mean</th>
      <th>sd</th>
      <th>hdi_3%</th>
      <th>hdi_97%</th>
      <th>mcse_mean</th>
      <th>mcse_sd</th>
      <th>ess_mean</th>
      <th>ess_sd</th>
      <th>ess_bulk</th>
      <th>ess_tail</th>
      <th>r_hat</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>a</th>
      <td>1.49</td>
      <td>0.05</td>
      <td>1.40</td>
      <td>1.59</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>2264.20</td>
      <td>2264.20</td>
      <td>2258.64</td>
      <td>2569.27</td>
      <td>1.00</td>
    </tr>
    <tr>
      <th>sigma_a</th>
      <td>0.32</td>
      <td>0.04</td>
      <td>0.24</td>
      <td>0.41</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1248.56</td>
      <td>1248.56</td>
      <td>1213.04</td>
      <td>1615.95</td>
      <td>1.01</td>
    </tr>
    <tr>
      <th>b</th>
      <td>-0.66</td>
      <td>0.07</td>
      <td>-0.80</td>
      <td>-0.54</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>3335.23</td>
      <td>3335.23</td>
      <td>3303.54</td>
      <td>2909.08</td>
      <td>1.00</td>
    </tr>
    <tr>
      <th>sigma</th>
      <td>0.73</td>
      <td>0.02</td>
      <td>0.69</td>
      <td>0.76</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>4975.12</td>
      <td>4953.96</td>
      <td>5015.64</td>
      <td>2859.70</td>
      <td>1.00</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>As we suspected, the estimate for the <code class="docutils literal notranslate"><span class="pre">no_stim</span></code> coefficient is reliably negative and centered around -0.66. This can be interpreted as neurons without stims having about half (<span class="math notranslate nohighlight">\(\exp(-0.66) = 0.52\)</span>) the firingrate levels of those with stims, after accounting for mouse. Note that this is only the <em>relative</em> effect of no_stim on firingrate levels: conditional on being in a given mouse, firingrate is expected to be half lower in neurons without stims than in neurons with. To see how much difference a stim makes on the <em>absolute</em> level of firingrate, we’d have to push the parameters through the model, as we do with posterior predictive checks and as we’ll do just now.</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># HIDE CODE</span>

<span class="n">xvals</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
<span class="n">avg_a_mouse</span> <span class="o">=</span> <span class="n">varying_intercept_trace</span><span class="p">[</span><span class="s2">&quot;a_mouse&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="n">avg_b</span> <span class="o">=</span> <span class="n">varying_intercept_trace</span><span class="p">[</span><span class="s2">&quot;b&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>

<span class="k">for</span> <span class="n">a_c</span> <span class="ow">in</span> <span class="n">avg_a_mouse</span><span class="p">:</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">xvals</span><span class="p">,</span> <span class="n">a_c</span> <span class="o">+</span> <span class="n">avg_b</span> <span class="o">*</span> <span class="n">xvals</span><span class="p">,</span> <span class="s1">&#39;ko-&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="s2">&quot;stim&quot;</span><span class="p">,</span> <span class="s2">&quot;no_stim&quot;</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Mean log firingrate&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;MEAN LOG firingrate BY mouse&quot;</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/multilevel_modeling_neurons_66_0.png" src="../_images/multilevel_modeling_neurons_66_0.png" />
</div>
</div>
<p>The graph above shows, for each mouse, the expected log firingrate level and the average effect of having no stim – these are the absolute effects we were talking about. Two caveats though:</p>
<ol class="simple">
<li><p>This graph doesn’t show the uncertainty for each mouse – how confident are we that the average estimates are where the graph shows? For that we’d need to combine the uncertainty in <code class="docutils literal notranslate"><span class="pre">a_mouse</span></code> and <code class="docutils literal notranslate"><span class="pre">b</span></code>, and this would of course vary by mouse. I didn’t show it here because the graph would get cluttered, but go ahead and do it for a subset of mice.</p></li>
<li><p>These are only <em>average</em> estimates at the <em>mouse-level</em> (<code class="docutils literal notranslate"><span class="pre">theta</span></code> in the model): they don’t take into account the variation by neuron. To add this other layer of uncertainty we’d need to take stock of the effect of <code class="docutils literal notranslate"><span class="pre">sigma</span></code> and generate samples from the <code class="docutils literal notranslate"><span class="pre">y</span></code> variable to see the effect on given neurons (that’s exactly the role of posterior predictive checks).</p></li>
</ol>
<p>That being said, it is easy to show that the partial pooling model provides more objectively reasonable estimates than either the pooled or unpooled models, at least for mice with small sample sizes:</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># HIDE CODE</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">7</span><span class="p">),</span> <span class="n">sharey</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">sharex</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">axes</span> <span class="o">=</span> <span class="n">axes</span><span class="o">.</span><span class="n">ravel</span><span class="p">()</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">c</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">SAMPLE_mice</span><span class="p">):</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">srrs_mn</span><span class="o">.</span><span class="n">no_stim</span><span class="p">[</span><span class="n">srrs_mn</span><span class="o">.</span><span class="n">mouse</span><span class="o">==</span><span class="n">c</span><span class="p">]</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">srrs_mn</span><span class="o">.</span><span class="n">log_firingrate</span><span class="p">[</span><span class="n">srrs_mn</span><span class="o">.</span><span class="n">mouse</span><span class="o">==</span><span class="n">c</span><span class="p">]</span>
    
    <span class="c1"># plot obs:</span>
    <span class="n">axes</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">x</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">))</span><span class="o">*</span><span class="mf">0.01</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.4</span><span class="p">)</span>
    <span class="c1"># complete-pooling model:</span>
    <span class="n">axes</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="n">a_stim</span><span class="p">,</span> <span class="n">a_no_stim</span><span class="p">],</span> <span class="s2">&quot;r--&quot;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Complete pooling&quot;</span><span class="p">)</span>
    <span class="c1"># no-pooling model:</span>
    <span class="n">axes</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span>
        <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> 
        <span class="p">[</span><span class="n">unpooled_stim</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">c</span><span class="p">,</span> <span class="s2">&quot;stim&quot;</span><span class="p">]</span> <span class="p">,</span> <span class="n">unpooled_no_stim</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">c</span><span class="p">,</span> <span class="s2">&quot;no_stim&quot;</span><span class="p">]],</span>
        <span class="s2">&quot;k:&quot;</span><span class="p">,</span>
        <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span>
        <span class="n">label</span><span class="o">=</span><span class="s2">&quot;No pooling&quot;</span>
    <span class="p">)</span>
    <span class="c1"># partial-pooling model:</span>
    <span class="n">axes</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span>
        <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> 
        <span class="p">[</span><span class="n">avg_a_mouse</span><span class="p">[</span><span class="n">mouse_lookup</span><span class="p">[</span><span class="n">c</span><span class="p">]],</span> <span class="n">avg_a_mouse</span><span class="p">[</span><span class="n">mouse_lookup</span><span class="p">[</span><span class="n">c</span><span class="p">]]</span> <span class="o">+</span> <span class="n">avg_b</span><span class="p">],</span>
        <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Partial pooling&quot;</span>
    <span class="p">)</span>
    
    <span class="n">axes</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">set_xticks</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">])</span>
    <span class="n">axes</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">set_xticklabels</span><span class="p">([</span><span class="s2">&quot;stim&quot;</span><span class="p">,</span> <span class="s2">&quot;no_stim&quot;</span><span class="p">])</span>
    <span class="n">axes</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="n">c</span><span class="p">)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">i</span><span class="o">%</span><span class="k">2</span>:
        <span class="n">axes</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;Log firingrate level&quot;</span><span class="p">)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">i</span><span class="o">%</span><span class="k">4</span>:
        <span class="n">axes</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">fontsize</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">frameon</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">();</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/multilevel_modeling_neurons_68_0.png" src="../_images/multilevel_modeling_neurons_68_0.png" />
</div>
</div>
<p>Here we clearly see the notion that partial-pooling is a compromise between no pooling and complete pooling, as its mean estimates are usually between the other models’ estimates. And interestingly, the bigger (smaller) the sample size in a given mouse, the closer the partial-pooling estimates are to the no-pooling (complete-pooling) estimates.</p>
<p>We see however that mice vary by more than just their baseline rates: the effect of no_stim seems to be different from one mouse to another. It would be great if our model could take that into account, wouldn’t it? Well to do that, we need to allow the slope to vary by mouse – not only the intercept – and here is how you can do it with PyMC3.</p>
</div>
<div class="section" id="varying-intercept-and-slope-model">
<h2>Varying intercept and slope model<a class="headerlink" href="#varying-intercept-and-slope-model" title="Permalink to this headline">¶</a></h2>
<p>The most general model allows both the intercept and slope to vary by mouse:</p>
<div class="math notranslate nohighlight">
\[y_i = \alpha_{j[i]} + \beta_{j[i]} x_{i} + \epsilon_i\]</div>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># HIDE CODE</span>

<span class="k">with</span> <span class="n">pm</span><span class="o">.</span><span class="n">Model</span><span class="p">()</span> <span class="k">as</span> <span class="n">varying_intercept_slope</span><span class="p">:</span>
    <span class="c1"># Hyperpriors:</span>
    <span class="n">a</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="s1">&#39;a&#39;</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="mf">0.</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="mf">5.</span><span class="p">)</span>
    <span class="n">sigma_a</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Exponential</span><span class="p">(</span><span class="s1">&#39;sigma_a&#39;</span><span class="p">,</span> <span class="mf">1.</span><span class="p">)</span>
    <span class="n">b</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="s1">&#39;b&#39;</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="mf">0.</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="mf">1.</span><span class="p">)</span>
    <span class="n">sigma_b</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Exponential</span><span class="p">(</span><span class="s1">&#39;sigma_b&#39;</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">)</span>
    
    <span class="c1"># Varying intercepts:</span>
    <span class="n">a_mouse</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="s1">&#39;a_mouse&#39;</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="n">a</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="n">sigma_a</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="n">n_mice</span><span class="p">)</span>
    <span class="c1"># Varying slopes:</span>
    <span class="n">b_mouse</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="s1">&#39;b_mouse&#39;</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="n">b</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="n">sigma_b</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="n">n_mice</span><span class="p">)</span>
    
    <span class="c1"># Expected value per mouse:</span>
    <span class="n">theta</span> <span class="o">=</span> <span class="n">a_mouse</span><span class="p">[</span><span class="n">mouse</span><span class="p">]</span> <span class="o">+</span> <span class="n">b_mouse</span><span class="p">[</span><span class="n">mouse</span><span class="p">]</span> <span class="o">*</span> <span class="n">no_stim</span>
    <span class="c1"># Model error:</span>
    <span class="n">sigma</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Exponential</span><span class="p">(</span><span class="s1">&#39;sigma&#39;</span><span class="p">,</span> <span class="mf">1.</span><span class="p">)</span>
    
    <span class="n">y</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="s1">&#39;y&#39;</span><span class="p">,</span> <span class="n">theta</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="n">sigma</span><span class="p">,</span> <span class="n">observed</span><span class="o">=</span><span class="n">log_firingrate</span><span class="p">)</span>
<span class="n">pm</span><span class="o">.</span><span class="n">model_to_graphviz</span><span class="p">(</span><span class="n">varying_intercept_slope</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/multilevel_modeling_neurons_71_0.svg" src="../_images/multilevel_modeling_neurons_71_0.svg" /></div>
</div>
</div>
<div class="section" id="reparametrization">
<h2>Reparametrization<a class="headerlink" href="#reparametrization" title="Permalink to this headline">¶</a></h2>
<p>Now, if you run this model, you’ll get divergences (some or a lot, depending on your random seed). We don’t want that – divergences are your Voldemort to your models. In these situations it’s usually wise to reparametrize your model using the “non-centered parametrization” (I know, it’s really not a great term, but please indulge me). We’re not gonna explain it here, but there are <a class="reference external" href="https://twiecki.io/blog/2017/02/08/bayesian-hierchical-non-centered/">great resources out there</a>. In a nutshell, it’s an algebraic trick that helps computation but leaves the model unchanged – the model is statistically equivalent to the “centered” version. In that case, here is what it would look like:</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># HIDE CODE</span>

<span class="k">with</span> <span class="n">pm</span><span class="o">.</span><span class="n">Model</span><span class="p">()</span> <span class="k">as</span> <span class="n">varying_intercept_slope</span><span class="p">:</span>
    <span class="c1"># Hyperpriors:</span>
    <span class="n">a</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="s1">&#39;a&#39;</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="mf">0.</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="mf">5.</span><span class="p">)</span>
    <span class="n">sigma_a</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Exponential</span><span class="p">(</span><span class="s1">&#39;sigma_a&#39;</span><span class="p">,</span> <span class="mf">1.</span><span class="p">)</span>
    <span class="n">b</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="s1">&#39;b&#39;</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="mf">0.</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="mf">1.</span><span class="p">)</span>
    <span class="n">sigma_b</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Exponential</span><span class="p">(</span><span class="s1">&#39;sigma_b&#39;</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">)</span>
    
    <span class="c1"># Varying intercepts:</span>
    <span class="n">za_mouse</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="s1">&#39;za_mouse&#39;</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="mf">0.</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="mf">1.</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="n">n_mice</span><span class="p">)</span>
    <span class="c1"># Varying slopes:</span>
    <span class="n">zb_mouse</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="s1">&#39;zb_mouse&#39;</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="mf">0.</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="mf">1.</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="n">n_mice</span><span class="p">)</span>
    
    <span class="c1"># Expected value per mouse:</span>
    <span class="n">theta</span> <span class="o">=</span> <span class="p">(</span><span class="n">a</span> <span class="o">+</span> <span class="n">za_mouse</span><span class="p">[</span><span class="n">mouse</span><span class="p">]</span> <span class="o">*</span> <span class="n">sigma_a</span><span class="p">)</span> <span class="o">+</span> <span class="p">(</span><span class="n">b</span> <span class="o">+</span> <span class="n">zb_mouse</span><span class="p">[</span><span class="n">mouse</span><span class="p">]</span> <span class="o">*</span> <span class="n">sigma_b</span><span class="p">)</span> <span class="o">*</span> <span class="n">no_stim</span>
    <span class="c1"># Model error:</span>
    <span class="n">sigma</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Exponential</span><span class="p">(</span><span class="s1">&#39;sigma&#39;</span><span class="p">,</span> <span class="mf">1.</span><span class="p">)</span>
    
    <span class="n">y</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="s1">&#39;y&#39;</span><span class="p">,</span> <span class="n">theta</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="n">sigma</span><span class="p">,</span> <span class="n">observed</span><span class="o">=</span><span class="n">log_firingrate</span><span class="p">)</span>
<span class="n">pm</span><span class="o">.</span><span class="n">model_to_graphviz</span><span class="p">(</span><span class="n">varying_intercept_slope</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/multilevel_modeling_neurons_74_0.svg" src="../_images/multilevel_modeling_neurons_74_0.svg" /></div>
</div>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># HIDE CODE</span>

<span class="k">with</span> <span class="n">pm</span><span class="o">.</span><span class="n">Model</span><span class="p">()</span> <span class="k">as</span> <span class="n">varying_intercept_slope</span><span class="p">:</span>
    <span class="c1"># Hyperpriors:</span>
    <span class="n">a</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="s1">&#39;a&#39;</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="mf">0.</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="mf">5.</span><span class="p">)</span>
    <span class="n">sigma_a</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Exponential</span><span class="p">(</span><span class="s1">&#39;sigma_a&#39;</span><span class="p">,</span> <span class="mf">1.</span><span class="p">)</span>
    <span class="n">b</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="s1">&#39;b&#39;</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="mf">0.</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="mf">1.</span><span class="p">)</span>
    <span class="n">sigma_b</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Exponential</span><span class="p">(</span><span class="s1">&#39;sigma_b&#39;</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">)</span>
    
    <span class="c1"># Varying intercepts:</span>
    <span class="n">za_mouse</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="s1">&#39;za_mouse&#39;</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="mf">0.</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="mf">1.</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="n">n_mice</span><span class="p">)</span>
    <span class="c1"># Varying slopes:</span>
    <span class="n">zb_mouse</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="s1">&#39;zb_mouse&#39;</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="mf">0.</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="mf">1.</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="n">n_mice</span><span class="p">)</span>
    
    <span class="c1"># Expected value per mouse:</span>
    <span class="n">aa</span><span class="o">=</span><span class="n">pm</span><span class="o">.</span><span class="n">Deterministic</span><span class="p">(</span><span class="s1">&#39;aa&#39;</span><span class="p">,</span> <span class="n">a</span> <span class="o">+</span> <span class="n">za_mouse</span><span class="p">[</span><span class="n">mouse</span><span class="p">]</span> <span class="o">*</span> <span class="n">sigma_a</span><span class="p">)</span>
    <span class="n">bb</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Deterministic</span><span class="p">(</span><span class="s1">&#39;bb&#39;</span><span class="p">,</span> <span class="n">b</span> <span class="o">+</span> <span class="n">zb_mouse</span><span class="p">[</span><span class="n">mouse</span><span class="p">]</span> <span class="o">*</span> <span class="n">sigma_b</span><span class="p">)</span>
    <span class="n">theta</span> <span class="o">=</span> <span class="n">aa</span> <span class="o">+</span> <span class="n">bb</span> <span class="o">*</span> <span class="n">no_stim</span>
    <span class="c1"># Model error:</span>
    <span class="n">sigma</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Exponential</span><span class="p">(</span><span class="s1">&#39;sigma&#39;</span><span class="p">,</span> <span class="mf">1.</span><span class="p">)</span>
    
    <span class="n">y</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="s1">&#39;y&#39;</span><span class="p">,</span> <span class="n">theta</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="n">sigma</span><span class="p">,</span> <span class="n">observed</span><span class="o">=</span><span class="n">log_firingrate</span><span class="p">)</span>
<span class="n">pm</span><span class="o">.</span><span class="n">model_to_graphviz</span><span class="p">(</span><span class="n">varying_intercept_slope</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/multilevel_modeling_neurons_75_0.svg" src="../_images/multilevel_modeling_neurons_75_0.svg" /></div>
</div>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># HIDE CODE</span>

<span class="k">with</span> <span class="n">varying_intercept_slope</span><span class="p">:</span>    
    <span class="n">varying_intercept_slope_trace</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="mi">1000</span><span class="p">,</span> <span class="n">tune</span><span class="o">=</span><span class="mi">6000</span><span class="p">,</span> <span class="n">target_accept</span><span class="o">=</span><span class="mf">0.99</span><span class="p">,</span> <span class="n">random_seed</span><span class="o">=</span><span class="n">RANDOM_SEED</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Auto-assigning NUTS sampler...
Initializing NUTS using jitter+adapt_diag...
Multiprocess sampling (4 chains in 4 jobs)
NUTS: [sigma, zb_mouse, za_mouse, sigma_b, b, sigma_a, a]
</pre></div>
</div>
<div class="output text_html">
<div>
    <style>
        /* Turns off some styling */
        progress {
            /* gets rid of default border in Firefox and Opera. */
            border: none;
            /* Needs to be in here for Safari polyfill so background images work as expected. */
            background-size: auto;
        }
        .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
            background: #F44336;
        }
    </style>
  <progress value='28000' class='' max='28000' style='width:300px; height:20px; vertical-align: middle;'></progress>
  100.00% [28000/28000 01:39<00:00 Sampling 4 chains, 0 divergences]
</div>
</div><div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Sampling 4 chains for 6_000 tune and 1_000 draw iterations (24_000 + 4_000 draws total) took 100 seconds.
The number of effective samples is smaller than 25% for some parameters.
</pre></div>
</div>
</div>
</div>
<p>True, the code is uglier (for you, not for the computer), but:</p>
<ol class="simple">
<li><p>The interpretation stays pretty much the same: <code class="docutils literal notranslate"><span class="pre">a</span></code> and <code class="docutils literal notranslate"><span class="pre">b</span></code> are still the mean cohort-wide intercept and slope. <code class="docutils literal notranslate"><span class="pre">sigma_a</span></code> and <code class="docutils literal notranslate"><span class="pre">sigma_b</span></code> still estimate the dispersion across mice of the intercepts and slopes (the more alike the mice, the smaller the corresponding sigma). The big change is that now the mice estimates (<code class="docutils literal notranslate"><span class="pre">za_mouse</span></code> and <code class="docutils literal notranslate"><span class="pre">zb_mouse</span></code>) are z-scores. But the strategy to see what this means for mean firingrate levels per mouse is the same: push all these parameters through the model to get samples from <code class="docutils literal notranslate"><span class="pre">theta</span></code>.</p></li>
<li><p>We don’t have any divergence: the model sampled more efficiently and converged more quickly than in the centered form.</p></li>
</ol>
<p>Notice however that we had to increase the number of tuning steps. Looking at the trace helps us understand why:</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># HIDE CODE</span>

<span class="n">az</span><span class="o">.</span><span class="n">plot_trace</span><span class="p">(</span><span class="n">varying_intercept_slope_trace</span><span class="p">,</span> <span class="n">compact</span><span class="o">=</span><span class="kc">True</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/multilevel_modeling_neurons_78_0.png" src="../_images/multilevel_modeling_neurons_78_0.png" />
</div>
</div>
<p>All chains look good and we get a negative <code class="docutils literal notranslate"><span class="pre">b</span></code> coefficient, illustrating the mean downward effect of no-stim on firingrate levels at the cohort level. But notice that <code class="docutils literal notranslate"><span class="pre">sigma_b</span></code> often gets very near zero – which would indicate that mice don’t vary that much in their answer to the <code class="docutils literal notranslate"><span class="pre">no_stim</span></code> “treatment”. That’s probably what bugged MCMC when using the centered parametrization: these situations usually yield a weird geometry for the sampler, causing the divergences. In other words, the non-centered form often perfoms better when one of the sigmas gets close to zero. But here, even with the non-centered model the sampler is not that comfortable with <code class="docutils literal notranslate"><span class="pre">sigma_b</span></code>: in fact if you look at the estimates with <code class="docutils literal notranslate"><span class="pre">az.summary</span></code> you’ll probably see that the number of effective samples is quite low for <code class="docutils literal notranslate"><span class="pre">sigma_b</span></code>.</p>
<p>Also note that <code class="docutils literal notranslate"><span class="pre">sigma_a</span></code> is not that big either – i.e mice do differ in their baseline firingrate levels, but not by a lot. However we don’t that much of a problem to sample from this distribution because it’s much narrower than <code class="docutils literal notranslate"><span class="pre">sigma_b</span></code> and doesn’t get dangerously close to 0.</p>
<p>To wrap up this model, let’s plot the relationship between firingrate and no_stim for each mouse:</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># HIDE CODE</span>

<span class="n">xvals</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
<span class="n">avg_a_mouse</span> <span class="o">=</span> <span class="p">(</span>
    <span class="n">varying_intercept_slope_trace</span><span class="p">[</span><span class="s2">&quot;a&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span> 
    <span class="o">+</span> <span class="n">varying_intercept_slope_trace</span><span class="p">[</span><span class="s2">&quot;za_mouse&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span> 
    <span class="o">*</span> <span class="n">varying_intercept_slope_trace</span><span class="p">[</span><span class="s2">&quot;sigma_a&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
<span class="p">)</span>
<span class="n">avg_b_mouse</span> <span class="o">=</span> <span class="p">(</span>
    <span class="n">varying_intercept_slope_trace</span><span class="p">[</span><span class="s2">&quot;b&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span> 
    <span class="o">+</span> <span class="n">varying_intercept_slope_trace</span><span class="p">[</span><span class="s2">&quot;zb_mouse&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span> 
    <span class="o">*</span> <span class="n">varying_intercept_slope_trace</span><span class="p">[</span><span class="s2">&quot;sigma_b&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
<span class="p">)</span>

<span class="k">for</span> <span class="n">a_c</span><span class="p">,</span> <span class="n">b_c</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">avg_a_mouse</span><span class="p">,</span> <span class="n">avg_b_mouse</span><span class="p">):</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">xvals</span><span class="p">,</span> <span class="n">a_c</span> <span class="o">+</span> <span class="n">b_c</span> <span class="o">*</span> <span class="n">xvals</span><span class="p">,</span> <span class="s1">&#39;ko-&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.4</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="s2">&quot;stim&quot;</span><span class="p">,</span> <span class="s2">&quot;no_stim&quot;</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Mean log firingrate&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;MEAN LOG firingrate BY mouse&quot;</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/multilevel_modeling_neurons_80_0.png" src="../_images/multilevel_modeling_neurons_80_0.png" />
</div>
</div>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># HIDE CODE</span>

<span class="n">_</span><span class="o">=</span><span class="n">az</span><span class="o">.</span><span class="n">plot_posterior</span><span class="p">(</span><span class="n">varying_intercept_slope_trace</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>/home/m/anaconda3/envs/tf/lib/python3.6/site-packages/arviz/plots/plot_utils.py:563: UserWarning: rcParams[&#39;plot.max_subplots&#39;] (40) is smaller than the number of variables to plot (2013) in plot_posterior, generating only 40 plots
  UserWarning,
</pre></div>
</div>
<img alt="../_images/multilevel_modeling_neurons_81_1.png" src="../_images/multilevel_modeling_neurons_81_1.png" />
</div>
</div>
<p>With the same caveats as earlier, we can see that now <em>both</em> the intercept and the slope vary by mouse – and isn’t that a marvel of statistics? But wait, there is more!</p>
<p>We can (and maybe should) take into account the covariation between intercepts and slopes: when baseline firingrate is low in a given mouse, maybe that means the difference between no_stim and stim measurements will decrease – because there isn’t that much firingrate anyway. That would translate into a positive correlation between <code class="docutils literal notranslate"><span class="pre">a_mouse</span></code> and <code class="docutils literal notranslate"><span class="pre">b_mouse</span></code>, and adding that into our model would make even more efficient use the available data.</p>
<p>Or maybe the correlation is negative? In any case, we can’t know that unless we model it. To do that, we’ll use a multivariate Normal distribution instead of two different Normals for <code class="docutils literal notranslate"><span class="pre">a_mouse</span></code> and <code class="docutils literal notranslate"><span class="pre">b_mouse</span></code>. This simply means that each mouse’s parameters come from a common distribution with mean <code class="docutils literal notranslate"><span class="pre">a</span></code> for intercepts and <code class="docutils literal notranslate"><span class="pre">b</span></code> for slopes, and slopes and intercepts co-vary according to the covariance matrix <code class="docutils literal notranslate"><span class="pre">S</span></code>. In mathematical form:</p>
<div class="math notranslate nohighlight">
\[
y\sim Normal(\firingrate, \sigma)
\]</div>
<div class="math notranslate nohighlight">
\[\firingrate = \alpha_{mouse} + \beta_{mouse} \times no_stim\]</div>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{bmatrix} \alpha_{mouse} \\ \beta_{mouse} \end{bmatrix} \sim MvNormal(\begin{bmatrix} \alpha \\ \beta \end{bmatrix}, \Sigma)\end{split}\]</div>
<div class="math notranslate nohighlight">
\[\begin{split}\Sigma = \begin{pmatrix} \sigma_{\alpha} &amp; 0 \\ 0 &amp; \sigma_{\beta} \end{pmatrix}
     P
     \begin{pmatrix} \sigma_{\alpha} &amp; 0 \\ 0 &amp; \sigma_{\beta} \end{pmatrix}\end{split}\]</div>
<p>where <span class="math notranslate nohighlight">\(\alpha\)</span> and <span class="math notranslate nohighlight">\(\beta\)</span> are the mean intercept and slope respectively, <span class="math notranslate nohighlight">\(\sigma_{\alpha}\)</span> and <span class="math notranslate nohighlight">\(\sigma_{\beta}\)</span> represent the variation in intercepts and slopes respectively, and <span class="math notranslate nohighlight">\(P\)</span> is the correlation matrix of intercepts and slopes. In this case, as their is only one slope, <span class="math notranslate nohighlight">\(P\)</span> contains only one relevant figure: the correlation between <span class="math notranslate nohighlight">\(\alpha\)</span> and <span class="math notranslate nohighlight">\(\beta\)</span>.</p>
<p>This translates quite easily in PyMC3:</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># HIDE CODE</span>

<span class="k">with</span> <span class="n">pm</span><span class="o">.</span><span class="n">Model</span><span class="p">()</span> <span class="k">as</span> <span class="n">covariation_intercept_slope</span><span class="p">:</span>
    <span class="c1"># prior stddev in intercepts &amp; slopes (variation across mice):</span>
    <span class="n">sd_dist</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Exponential</span><span class="o">.</span><span class="n">dist</span><span class="p">(</span><span class="mf">0.5</span><span class="p">)</span>
    <span class="n">packed_chol</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">LKJCholeskyCov</span><span class="p">(</span><span class="s1">&#39;packed_chol&#39;</span><span class="p">,</span> <span class="n">eta</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">n</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">sd_dist</span><span class="o">=</span><span class="n">sd_dist</span><span class="p">)</span>
    <span class="n">chol</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">expand_packed_triangular</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="n">packed_chol</span><span class="p">,</span> <span class="n">lower</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    
    <span class="c1"># extract standard deviations and rho:</span>
    <span class="n">cov</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">chol</span><span class="p">,</span> <span class="n">chol</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>
    <span class="n">sigma_ab</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Deterministic</span><span class="p">(</span><span class="s1">&#39;sigma_ab&#39;</span><span class="p">,</span> <span class="n">tt</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">tt</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">cov</span><span class="p">)))</span>
    <span class="n">corr</span> <span class="o">=</span> <span class="n">tt</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">sigma_ab</span><span class="o">**-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">cov</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">tt</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">sigma_ab</span><span class="o">**-</span><span class="mi">1</span><span class="p">)))</span>
    <span class="n">r</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Deterministic</span><span class="p">(</span><span class="s1">&#39;Rho&#39;</span><span class="p">,</span> <span class="n">corr</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">triu_indices</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="mi">1</span><span class="p">)])</span>
    
    <span class="c1"># prior for average intercept:</span>
    <span class="n">a</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="s1">&#39;a&#39;</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="mf">0.</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="mf">5.</span><span class="p">)</span>
    <span class="c1"># prior for average slope:</span>
    <span class="n">b</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="s1">&#39;b&#39;</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="mf">0.</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="mf">1.</span><span class="p">)</span>
    <span class="c1"># population of varying effects:</span>
    <span class="n">ab_mouse</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">MvNormal</span><span class="p">(</span><span class="s1">&#39;ab_mouse&#39;</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="n">tt</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">]),</span> <span class="n">chol</span><span class="o">=</span><span class="n">chol</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">n_mice</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>
    
    <span class="c1"># Expected value per mouse:</span>
    <span class="n">theta</span> <span class="o">=</span> <span class="n">ab_mouse</span><span class="p">[</span><span class="n">mouse</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="n">ab_mouse</span><span class="p">[</span><span class="n">mouse</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="n">no_stim</span>
    <span class="c1"># Model error:</span>
    <span class="n">sigma</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Exponential</span><span class="p">(</span><span class="s1">&#39;sigma&#39;</span><span class="p">,</span> <span class="mf">1.</span><span class="p">)</span>
    
    <span class="n">y</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="s1">&#39;y&#39;</span><span class="p">,</span> <span class="n">theta</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="n">sigma</span><span class="p">,</span> <span class="n">observed</span><span class="o">=</span><span class="n">log_firingrate</span><span class="p">)</span>
<span class="n">pm</span><span class="o">.</span><span class="n">model_to_graphviz</span><span class="p">(</span><span class="n">covariation_intercept_slope</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/multilevel_modeling_neurons_85_0.svg" src="../_images/multilevel_modeling_neurons_85_0.svg" /></div>
</div>
<p>This is by far the most complex model we’ve done so far, so it’s normal if you’re confused. Just take some time to let it sink in. The centered version mirrors the mathematical notions very closely, so you should be able to get the gist of it. Of course, you guessed it, we’re gonna need the non-centered version. There is actually just one change:</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># HIDE CODE</span>

<span class="k">with</span> <span class="n">pm</span><span class="o">.</span><span class="n">Model</span><span class="p">()</span> <span class="k">as</span> <span class="n">covariation_intercept_slope</span><span class="p">:</span>
    <span class="c1"># prior stddev in intercepts &amp; slopes (variation across mice):</span>
    <span class="n">sd_dist</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Exponential</span><span class="o">.</span><span class="n">dist</span><span class="p">(</span><span class="mf">0.5</span><span class="p">)</span>
    <span class="n">packed_chol</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">LKJCholeskyCov</span><span class="p">(</span><span class="s1">&#39;packed_chol&#39;</span><span class="p">,</span> <span class="n">eta</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">n</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">sd_dist</span><span class="o">=</span><span class="n">sd_dist</span><span class="p">)</span>
    <span class="n">chol</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">expand_packed_triangular</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="n">packed_chol</span><span class="p">,</span> <span class="n">lower</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    
    <span class="c1"># extract standard deviations and rho:</span>
    <span class="n">cov</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">chol</span><span class="p">,</span> <span class="n">chol</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>
    <span class="n">sigma_ab</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Deterministic</span><span class="p">(</span><span class="s1">&#39;sigma_ab&#39;</span><span class="p">,</span> <span class="n">tt</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">tt</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">cov</span><span class="p">)))</span>
    <span class="n">corr</span> <span class="o">=</span> <span class="n">tt</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">sigma_ab</span><span class="o">**-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">cov</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">tt</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">sigma_ab</span><span class="o">**-</span><span class="mi">1</span><span class="p">)))</span>
    <span class="n">r</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Deterministic</span><span class="p">(</span><span class="s1">&#39;Rho&#39;</span><span class="p">,</span> <span class="n">corr</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">triu_indices</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="mi">1</span><span class="p">)])</span>
    
    <span class="c1"># prior for average intercept:</span>
    <span class="n">a</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="s1">&#39;a&#39;</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="mf">0.</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="mf">5.</span><span class="p">)</span>
    <span class="c1"># prior for average slope:</span>
    <span class="n">b</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="s1">&#39;b&#39;</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="mf">0.</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="mf">1.</span><span class="p">)</span>
    <span class="c1"># population of varying effects:</span>
    <span class="n">z</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="s1">&#39;z&#39;</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="n">n_mice</span><span class="p">))</span>
    <span class="n">ab_mouse</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Deterministic</span><span class="p">(</span><span class="s1">&#39;ab_mouse&#39;</span><span class="p">,</span> <span class="n">tt</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">chol</span><span class="p">,</span> <span class="n">z</span><span class="p">)</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>
    
    <span class="c1"># Expected value per mouse:</span>
    <span class="n">theta</span> <span class="o">=</span> <span class="n">a</span> <span class="o">+</span> <span class="n">ab_mouse</span><span class="p">[</span><span class="n">mouse</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="p">(</span><span class="n">b</span> <span class="o">+</span> <span class="n">ab_mouse</span><span class="p">[</span><span class="n">mouse</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span> <span class="o">*</span> <span class="n">no_stim</span>
    <span class="c1"># Model error:</span>
    <span class="n">sigma</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Exponential</span><span class="p">(</span><span class="s1">&#39;sigma&#39;</span><span class="p">,</span> <span class="mf">1.</span><span class="p">)</span>
    
    <span class="n">y</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="s1">&#39;y&#39;</span><span class="p">,</span> <span class="n">theta</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="n">sigma</span><span class="p">,</span> <span class="n">observed</span><span class="o">=</span><span class="n">log_firingrate</span><span class="p">)</span>
    <span class="n">covariation_intercept_slope_trace</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="mi">1000</span><span class="p">,</span> <span class="n">tune</span><span class="o">=</span><span class="mi">6000</span><span class="p">,</span> <span class="n">target_accept</span><span class="o">=</span><span class="mf">0.99</span><span class="p">,</span> <span class="n">random_seed</span><span class="o">=</span><span class="n">RANDOM_SEED</span><span class="p">)</span>
    
<span class="n">az</span><span class="o">.</span><span class="n">plot_trace</span><span class="p">(</span><span class="n">covariation_intercept_slope_trace</span><span class="p">,</span> <span class="n">lines</span><span class="o">=</span><span class="p">[(</span><span class="s2">&quot;Rho&quot;</span><span class="p">,</span> <span class="p">{},</span> <span class="mf">0.</span><span class="p">)],</span> <span class="n">compact</span><span class="o">=</span><span class="kc">True</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Auto-assigning NUTS sampler...
Initializing NUTS using jitter+adapt_diag...
Multiprocess sampling (4 chains in 4 jobs)
NUTS: [sigma, z, b, a, packed_chol]
</pre></div>
</div>
<div class="output text_html">
<div>
    <style>
        /* Turns off some styling */
        progress {
            /* gets rid of default border in Firefox and Opera. */
            border: none;
            /* Needs to be in here for Safari polyfill so background images work as expected. */
            background-size: auto;
        }
        .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
            background: #F44336;
        }
    </style>
  <progress value='28000' class='' max='28000' style='width:300px; height:20px; vertical-align: middle;'></progress>
  100.00% [28000/28000 03:22<00:00 Sampling 4 chains, 0 divergences]
</div>
</div><div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Sampling 4 chains for 6_000 tune and 1_000 draw iterations (24_000 + 4_000 draws total) took 203 seconds.
The number of effective samples is smaller than 25% for some parameters.
</pre></div>
</div>
<img alt="../_images/multilevel_modeling_neurons_87_3.png" src="../_images/multilevel_modeling_neurons_87_3.png" />
</div>
</div>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># HIDE CODE</span>

<span class="n">pm</span><span class="o">.</span><span class="n">model_to_graphviz</span><span class="p">(</span><span class="n">covariation_intercept_slope</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/multilevel_modeling_neurons_88_0.svg" src="../_images/multilevel_modeling_neurons_88_0.svg" /></div>
</div>
<p>So the correlation between slopes and intercepts seems to be negative: when <code class="docutils literal notranslate"><span class="pre">a_mouse</span></code> increases, <code class="docutils literal notranslate"><span class="pre">b_mouse</span></code> tends to decrease. In other words, when stim firingrate in a mouse gets bigger, the difference with no_stim firingrate tends to get bigger too (because no_stim readings get smaller while stim readings get bigger). But again, the uncertainty is wide on <code class="docutils literal notranslate"><span class="pre">Rho</span></code> so it’s possible the correlation goes the other way around or is simply close to zero.</p>
<p>And how much variation is there across mice? It’s not easy to read <code class="docutils literal notranslate"><span class="pre">sigma_ab</span></code> above, so let’s do a forest plot and compare the estimates with the model that doesn’t include the covariation between slopes and intercepts:</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># HIDE CODE</span>

<span class="n">az</span><span class="o">.</span><span class="n">plot_forest</span><span class="p">(</span>
    <span class="p">[</span><span class="n">varying_intercept_slope_trace</span><span class="p">,</span> <span class="n">covariation_intercept_slope_trace</span><span class="p">],</span> 
    <span class="n">model_names</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;No covariation.&quot;</span><span class="p">,</span> <span class="s2">&quot;With covariation&quot;</span><span class="p">],</span> 
    <span class="n">var_names</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;a&quot;</span><span class="p">,</span> <span class="s2">&quot;b&quot;</span><span class="p">,</span> <span class="s2">&quot;sigma_a&quot;</span><span class="p">,</span> <span class="s2">&quot;sigma_b&quot;</span><span class="p">,</span> <span class="s2">&quot;sigma_ab&quot;</span><span class="p">,</span> <span class="s2">&quot;Rho&quot;</span><span class="p">],</span> 
    <span class="n">combined</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
<span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/multilevel_modeling_neurons_90_0.png" src="../_images/multilevel_modeling_neurons_90_0.png" />
</div>
</div>
<p>The estimates are very close to each other, both for the means and the standard deviations. But remember, the information given by <code class="docutils literal notranslate"><span class="pre">Rho</span></code> is only seen at the mouse level: in theory it uses even more information from the data to get an even more informed pooling of information for all mouse parameters. So let’s visually compare estimates of both models at the mouse level:</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># HIDE CODE</span>

<span class="c1"># posterior means of covariation model:</span>
<span class="n">a_mouse_cov</span> <span class="o">=</span> <span class="p">(</span>
    <span class="n">covariation_intercept_slope_trace</span><span class="p">[</span><span class="s1">&#39;a&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
    <span class="o">+</span> <span class="n">covariation_intercept_slope_trace</span><span class="p">[</span><span class="s1">&#39;ab_mouse&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)[:,</span> <span class="mi">0</span><span class="p">]</span>
<span class="p">)</span>
<span class="n">b_mouse_cov</span> <span class="o">=</span> <span class="p">(</span>
    <span class="n">covariation_intercept_slope_trace</span><span class="p">[</span><span class="s1">&#39;b&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
    <span class="o">+</span> <span class="n">covariation_intercept_slope_trace</span><span class="p">[</span><span class="s1">&#39;ab_mouse&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)[:,</span> <span class="mi">1</span><span class="p">]</span>
<span class="p">)</span>

<span class="c1"># plot both and connect with lines</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">avg_a_mouse</span><span class="p">,</span> <span class="n">avg_b_mouse</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;No cov estimates&quot;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.6</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">a_mouse_cov</span><span class="p">,</span> <span class="n">b_mouse_cov</span><span class="p">,</span> <span class="n">facecolors</span><span class="o">=</span><span class="s1">&#39;none&#39;</span><span class="p">,</span> <span class="n">edgecolors</span><span class="o">=</span><span class="s1">&#39;k&#39;</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;With cov estimates&quot;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.8</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="n">avg_a_mouse</span><span class="p">,</span> <span class="n">a_mouse_cov</span><span class="p">],</span> <span class="p">[</span><span class="n">avg_b_mouse</span><span class="p">,</span> <span class="n">b_mouse_cov</span><span class="p">],</span> <span class="s1">&#39;k-&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">.5</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Intercept&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Slope&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">();</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/multilevel_modeling_neurons_92_0.png" src="../_images/multilevel_modeling_neurons_92_0.png" />
</div>
</div>
<p>The negative correlation is somewhat clear here: when the intercept increases, the slope decreases. So we understand why the model put most of the posterior weight into negative territory for <code class="docutils literal notranslate"><span class="pre">Rho</span></code>. Nevertheless, the negativity isn’t <em>that</em> obvious, which is why the model gives a non-trivial posterior probability to the possibility that <code class="docutils literal notranslate"><span class="pre">Rho</span></code> could in fact be zero or positive.</p>
<p>Interestingly, the differences between both models occur at extreme slope and intercept values. This is because the second model used the slightly negative correlation between intercepts and slopes to adjust their estimates: when intercepts are <em>larger</em> (smaller) than average, the model pushes <em>down</em> (up) the associated slopes.</p>
<p>Globally, there is a lot of agreement here: modeling the correlation didn’t change inference that much. We already saw that firingrate levels tended to be lower in no_stims than stims, and when we checked the posterior distributions of the average effects (<code class="docutils literal notranslate"><span class="pre">a</span></code> and <code class="docutils literal notranslate"><span class="pre">b</span></code>) and standard deviations, we noticed that they were almost identical. But on average the model with covariation will be more accurate – because it squeezes additional information from the data, to shrink estimates in both dimensions.</p>
</div>
<div class="section" id="adding-group-level-predictors">
<h2>Adding group-level predictors<a class="headerlink" href="#adding-group-level-predictors" title="Permalink to this headline">¶</a></h2>
<p>A primary strength of multilevel models is the ability to handle predictors on multiple levels simultaneously. If we consider the varying-intercepts model above:</p>
<div class="math notranslate nohighlight">
\[y_i = \alpha_{j[i]} + \beta x_{i} + \epsilon_i\]</div>
<p>we may, instead of a simple random effect to describe variation in the expected firingrate value, specify another regression model with a mouse-level covariate. Here, we use the mouse velocity reading <span class="math notranslate nohighlight">\(u_j\)</span> (originally uranium level per county), which is thought to be related to firingrate levels:</p>
<div class="math notranslate nohighlight">
\[\alpha_j = \gamma_0 + \gamma_1 u_j + \zeta_j\]</div>
<div class="math notranslate nohighlight">
\[\zeta_j \sim N(0, \sigma_{\alpha}^2)\]</div>
<p>Thus, we are now incorporating a neuron-level predictor (no_stim or stim) as well as a mouse-level predictor (velocity).</p>
<p>Note that the model has both indicator variables for each mouse, plus a mouse-level covariate. In classical regression, this would result in collinearity. In a multilevel model, the partial pooling of the intercepts towards the expected value of the group-level linear model avoids this.</p>
<p>Group-level predictors also serve to reduce group-level variation, <span class="math notranslate nohighlight">\(\sigma_{\alpha}\)</span> (here it would be the variation across mice, <code class="docutils literal notranslate"><span class="pre">sigma_a</span></code>). An important implication of this is that the group-level estimate induces stronger pooling – by definition, a smaller <span class="math notranslate nohighlight">\(\sigma_{\alpha}\)</span> means a stronger shrinkage of mice parameters towards the overall cohort mean.</p>
<p>This is fairly straightforward to implement in PyMC3 – we just add another level:</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># HIDE CODE</span>

<span class="k">with</span> <span class="n">pm</span><span class="o">.</span><span class="n">Model</span><span class="p">()</span> <span class="k">as</span> <span class="n">hierarchical_intercept</span><span class="p">:</span>
    <span class="c1"># Hyperpriors:</span>
    <span class="n">g</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="s1">&#39;g_neuron&#39;</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="mf">0.</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="mf">10.</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
    <span class="n">sigma_a</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Exponential</span><span class="p">(</span><span class="s1">&#39;sigma_a&#39;</span><span class="p">,</span> <span class="mf">1.</span><span class="p">)</span>

    <span class="c1"># Varying intercepts velocity model:</span>
    <span class="n">a</span> <span class="o">=</span> <span class="n">g</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="n">g</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="n">u</span>
    <span class="n">a_mouse</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="s1">&#39;a_mouse&#39;</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="n">a</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="n">sigma_a</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="n">n_mice</span><span class="p">)</span>
    <span class="c1"># Common slope:</span>
    <span class="n">b</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="s1">&#39;b&#39;</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="mf">0.</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="mf">1.</span><span class="p">)</span>

    <span class="c1"># Expected value per mouse:</span>
    <span class="n">theta</span> <span class="o">=</span> <span class="n">a_mouse</span><span class="p">[</span><span class="n">mouse</span><span class="p">]</span> <span class="o">+</span> <span class="n">b</span> <span class="o">*</span> <span class="n">no_stim</span>
    <span class="c1"># Model error:</span>
    <span class="n">sigma</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Exponential</span><span class="p">(</span><span class="s1">&#39;sigma&#39;</span><span class="p">,</span> <span class="mf">1.</span><span class="p">)</span>

    <span class="n">y</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="s1">&#39;y&#39;</span><span class="p">,</span> <span class="n">theta</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="n">sigma</span><span class="p">,</span> <span class="n">observed</span><span class="o">=</span><span class="n">log_firingrate</span><span class="p">)</span>
<span class="n">pm</span><span class="o">.</span><span class="n">model_to_graphviz</span><span class="p">(</span><span class="n">hierarchical_intercept</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/multilevel_modeling_neurons_95_0.svg" src="../_images/multilevel_modeling_neurons_95_0.svg" /></div>
</div>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># HIDE CODE</span>

<span class="c1"># compare to no velocity:</span>
<span class="k">with</span> <span class="n">pm</span><span class="o">.</span><span class="n">Model</span><span class="p">()</span> <span class="k">as</span> <span class="n">varying_intercept_slope</span><span class="p">:</span>
    <span class="c1"># Hyperpriors:</span>
    <span class="n">a</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="s1">&#39;a&#39;</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="mf">0.</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="mf">5.</span><span class="p">)</span>
    <span class="n">sigma_a</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Exponential</span><span class="p">(</span><span class="s1">&#39;sigma_a&#39;</span><span class="p">,</span> <span class="mf">1.</span><span class="p">)</span>
    <span class="n">b</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="s1">&#39;b&#39;</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="mf">0.</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="mf">1.</span><span class="p">)</span>
    <span class="n">sigma_b</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Exponential</span><span class="p">(</span><span class="s1">&#39;sigma_b&#39;</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">)</span>
    
    <span class="c1"># Varying intercepts:</span>
    <span class="n">a_mouse</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="s1">&#39;a_mouse&#39;</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="n">a</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="n">sigma_a</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="n">n_mice</span><span class="p">)</span>
    <span class="c1"># Varying slopes:</span>
    <span class="n">b_mouse</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="s1">&#39;b_mouse&#39;</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="n">b</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="n">sigma_b</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="n">n_mice</span><span class="p">)</span>
    
    <span class="c1"># Expected value per mouse:</span>
    <span class="n">theta</span> <span class="o">=</span> <span class="n">a_mouse</span><span class="p">[</span><span class="n">mouse</span><span class="p">]</span> <span class="o">+</span> <span class="n">b_mouse</span><span class="p">[</span><span class="n">mouse</span><span class="p">]</span> <span class="o">*</span> <span class="n">no_stim</span>
    <span class="c1"># Model error:</span>
    <span class="n">sigma</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Exponential</span><span class="p">(</span><span class="s1">&#39;sigma&#39;</span><span class="p">,</span> <span class="mf">1.</span><span class="p">)</span>
    
    <span class="n">y</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="s1">&#39;y&#39;</span><span class="p">,</span> <span class="n">theta</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="n">sigma</span><span class="p">,</span> <span class="n">observed</span><span class="o">=</span><span class="n">log_firingrate</span><span class="p">)</span>
<span class="n">pm</span><span class="o">.</span><span class="n">model_to_graphviz</span><span class="p">(</span><span class="n">varying_intercept_slope</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/multilevel_modeling_neurons_96_0.svg" src="../_images/multilevel_modeling_neurons_96_0.svg" /></div>
</div>
<p>Do you see the new level, with <code class="docutils literal notranslate"><span class="pre">sigma_a</span></code> and <code class="docutils literal notranslate"><span class="pre">g</span></code>, which is two-dimensional because it contains the linear model for <code class="docutils literal notranslate"><span class="pre">a_mouse</span></code>? Now, if we run this model we’re gonna get… divergences, you guessed it! So we’re gonna switch to the non-centered form again:</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># HIDE CODE</span>

<span class="k">with</span> <span class="n">pm</span><span class="o">.</span><span class="n">Model</span><span class="p">()</span> <span class="k">as</span> <span class="n">hierarchical_intercept</span><span class="p">:</span>
    <span class="c1"># Hyperpriors:</span>
    <span class="n">g</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="s1">&#39;g&#39;</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="mf">0.</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="mf">10.</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
    <span class="n">sigma_a</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Exponential</span><span class="p">(</span><span class="s1">&#39;sigma_a&#39;</span><span class="p">,</span> <span class="mf">1.</span><span class="p">)</span>
    
    <span class="c1"># Varying intercepts velocity model:</span>
    <span class="n">a</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Deterministic</span><span class="p">(</span><span class="s1">&#39;a&#39;</span><span class="p">,</span> <span class="n">g</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="n">g</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="n">u</span><span class="p">)</span>
    <span class="n">za_mouse</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="s1">&#39;za_mouse&#39;</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="mf">0.</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="mf">1.</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="n">n_mice</span><span class="p">)</span>
    <span class="n">a_mouse</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Deterministic</span><span class="p">(</span><span class="s1">&#39;a_mouse&#39;</span><span class="p">,</span> <span class="n">a</span> <span class="o">+</span> <span class="n">za_mouse</span> <span class="o">*</span> <span class="n">sigma_a</span><span class="p">)</span>
    <span class="c1"># Common slope:</span>
    <span class="n">b</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="s1">&#39;b&#39;</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="mf">0.</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="mf">1.</span><span class="p">)</span>
    
    <span class="c1"># Expected value per mouse:</span>
    <span class="n">theta</span> <span class="o">=</span> <span class="n">a_mouse</span><span class="p">[</span><span class="n">mouse</span><span class="p">]</span> <span class="o">+</span> <span class="n">b</span> <span class="o">*</span> <span class="n">no_stim</span>
    <span class="c1"># Model error:</span>
    <span class="n">sigma</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Exponential</span><span class="p">(</span><span class="s1">&#39;sigma&#39;</span><span class="p">,</span> <span class="mf">1.</span><span class="p">)</span>
    
    <span class="n">y</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="s1">&#39;y&#39;</span><span class="p">,</span> <span class="n">theta</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="n">sigma</span><span class="p">,</span> <span class="n">observed</span><span class="o">=</span><span class="n">log_firingrate</span><span class="p">)</span>
    
<span class="n">pm</span><span class="o">.</span><span class="n">model_to_graphviz</span><span class="p">(</span><span class="n">hierarchical_intercept</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/multilevel_modeling_neurons_98_0.svg" src="../_images/multilevel_modeling_neurons_98_0.svg" /></div>
</div>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># HIDE CODE</span>

<span class="k">with</span> <span class="n">hierarchical_intercept</span><span class="p">:</span>    
    <span class="n">hierarchical_intercept_trace</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="mi">1000</span><span class="p">,</span> <span class="n">tune</span><span class="o">=</span><span class="mi">6000</span><span class="p">,</span> <span class="n">target_accept</span><span class="o">=</span><span class="mf">0.99</span><span class="p">,</span> <span class="n">random_seed</span><span class="o">=</span><span class="n">RANDOM_SEED</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Auto-assigning NUTS sampler...
Initializing NUTS using jitter+adapt_diag...
Multiprocess sampling (4 chains in 4 jobs)
NUTS: [sigma, b, za_mouse, sigma_a, g]
</pre></div>
</div>
<div class="output text_html">
<div>
    <style>
        /* Turns off some styling */
        progress {
            /* gets rid of default border in Firefox and Opera. */
            border: none;
            /* Needs to be in here for Safari polyfill so background images work as expected. */
            background-size: auto;
        }
        .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
            background: #F44336;
        }
    </style>
  <progress value='28000' class='' max='28000' style='width:300px; height:20px; vertical-align: middle;'></progress>
  100.00% [28000/28000 00:46<00:00 Sampling 4 chains, 0 divergences]
</div>
</div><div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Sampling 4 chains for 6_000 tune and 1_000 draw iterations (24_000 + 4_000 draws total) took 48 seconds.
</pre></div>
</div>
</div>
</div>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># HIDE CODE</span>

<span class="n">samples</span> <span class="o">=</span> <span class="n">hierarchical_intercept_trace</span>
<span class="n">avg_a</span> <span class="o">=</span> <span class="n">samples</span><span class="p">[</span><span class="s1">&#39;a&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="n">avg_a_mouse</span> <span class="o">=</span> <span class="n">samples</span><span class="p">[</span><span class="s1">&#39;a_mouse&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span>
    <span class="n">u</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">argsort</span><span class="p">(</span><span class="n">u</span><span class="p">)],</span> 
    <span class="n">avg_a</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">argsort</span><span class="p">(</span><span class="n">u</span><span class="p">)],</span> 
    <span class="s2">&quot;k--&quot;</span><span class="p">,</span> 
    <span class="n">alpha</span><span class="o">=</span><span class="mf">0.6</span><span class="p">,</span>
    <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Mean intercept&quot;</span>
<span class="p">)</span>
<span class="n">az</span><span class="o">.</span><span class="n">plot_hpd</span><span class="p">(</span>
    <span class="n">u</span><span class="p">,</span> 
    <span class="n">samples</span><span class="p">[</span><span class="s1">&#39;a&#39;</span><span class="p">],</span>
    <span class="n">fill_kwargs</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;alpha&quot;</span><span class="p">:</span> <span class="mf">0.1</span><span class="p">,</span> <span class="s2">&quot;color&quot;</span><span class="p">:</span> <span class="s2">&quot;k&quot;</span><span class="p">,</span> <span class="s2">&quot;label&quot;</span><span class="p">:</span> <span class="s2">&quot;Mean intercept HPD&quot;</span><span class="p">}</span>
<span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">u</span><span class="p">,</span> <span class="n">avg_a_mouse</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Mean mouse-intercept&quot;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">ui</span><span class="p">,</span> <span class="n">l</span><span class="p">,</span> <span class="n">h</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span>
    <span class="n">u</span><span class="p">,</span> 
    <span class="n">az</span><span class="o">.</span><span class="n">hpd</span><span class="p">(</span><span class="n">samples</span><span class="p">[</span><span class="s2">&quot;a_mouse&quot;</span><span class="p">])[:,</span> <span class="mi">0</span><span class="p">],</span> 
    <span class="n">az</span><span class="o">.</span><span class="n">hpd</span><span class="p">(</span><span class="n">samples</span><span class="p">[</span><span class="s2">&quot;a_mouse&quot;</span><span class="p">])[:,</span> <span class="mi">1</span><span class="p">]</span>
<span class="p">):</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="n">ui</span><span class="p">,</span> <span class="n">ui</span><span class="p">],</span> <span class="p">[</span><span class="n">l</span><span class="p">,</span> <span class="n">h</span><span class="p">],</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s2">&quot;orange&quot;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;mouse-level velocity&quot;</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Intercept estimate&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">fontsize</span><span class="o">=</span><span class="mi">9</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>/home/m/anaconda3/envs/tf/lib/python3.6/site-packages/arviz/data/base.py:146: UserWarning: More chains (4000) than draws (85). Passed array should have shape (chains, draws, *shape)
  UserWarning,
/home/m/anaconda3/envs/tf/lib/python3.6/site-packages/arviz/stats/stats.py:338: UserWarning: hpd will be deprecated Please replace hdi
  warnings.warn((&quot;hpd will be deprecated &quot; &quot;Please replace hdi&quot;),)
/home/m/anaconda3/envs/tf/lib/python3.6/site-packages/arviz/data/base.py:146: UserWarning: More chains (4000) than draws (85). Passed array should have shape (chains, draws, *shape)
  UserWarning,
</pre></div>
</div>
<img alt="../_images/multilevel_modeling_neurons_100_1.png" src="../_images/multilevel_modeling_neurons_100_1.png" />
</div>
</div>
<p>Velocity is indeed much associated with baseline firingrate levels in each mouse. The graph above shows the average relationship and its uncertainty: the baseline firingrate level in an average mouse as a function of velocity, as well as the 94% HPD of this firingrate level (grey line and envelope). The blue points and orange bars represent the relationship between baseline firingrate and velocity, but now for each mouse. As you see, the uncertainty is bigger now, because it adds on top of the average uncertainty – each mouse has its idyosyncracies after all.</p>
<p>If we compare the mouse-intercepts for this model with those of the partial-pooling model without a mouse-level covariate:</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># HIDE CODE</span>

<span class="n">az</span><span class="o">.</span><span class="n">plot_forest</span><span class="p">(</span>
    <span class="p">[</span><span class="n">varying_intercept_trace</span><span class="p">,</span> <span class="n">hierarchical_intercept_trace</span><span class="p">],</span> 
    <span class="n">model_names</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;W/t. mouse pred.&quot;</span><span class="p">,</span> <span class="s2">&quot;With mouse pred.&quot;</span><span class="p">],</span> 
    <span class="n">var_names</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;a_mouse&quot;</span><span class="p">],</span> 
    <span class="n">combined</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">40</span><span class="p">)</span>
<span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/multilevel_modeling_neurons_102_0.png" src="../_images/multilevel_modeling_neurons_102_0.png" />
</div>
</div>
<p>We see that the compatibility intervals are narrower for the model including the mouse-level covariate. This is expected, as the effect of a covariate is to reduce the variation in the outcome variable – provided the covariate is of predictive value. More importantly, with this model we were able to squeeze even more information out of the data.</p>
</div>
<div class="section" id="correlations-among-levels">
<h2>Correlations among levels<a class="headerlink" href="#correlations-among-levels" title="Permalink to this headline">¶</a></h2>
<p>In some instances, having predictors at multiple levels can reveal correlation between individual-level variables and group residuals. We can account for this by including the average of the individual predictors as a covariate in the model for the group intercept:</p>
<div class="math notranslate nohighlight">
\[\alpha_j = \gamma_0 + \gamma_1 u_j + \gamma_2 \bar{x} + \zeta_j\]</div>
<p>These are broadly referred to as <em><strong>contextual effects</strong></em>.</p>
<p>To add these effects to our model, let’s create a new variable containing the mean of <code class="docutils literal notranslate"><span class="pre">no_stim</span></code> in each mouse and add that to our previous model:</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># HIDE CODE</span>

<span class="n">avg_no_stim</span> <span class="o">=</span> <span class="n">srrs_mn</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="s1">&#39;mouse&#39;</span><span class="p">)[</span><span class="s1">&#39;no_stim&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="o">.</span><span class="n">rename</span><span class="p">(</span><span class="n">mouse_lookup</span><span class="p">)</span><span class="o">.</span><span class="n">values</span>

<span class="k">with</span> <span class="n">pm</span><span class="o">.</span><span class="n">Model</span><span class="p">()</span> <span class="k">as</span> <span class="n">contextual_effect</span><span class="p">:</span>
    <span class="c1"># Hyperpriors:</span>
    <span class="n">g</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="s1">&#39;g&#39;</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="mf">0.</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="mf">10.</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
    <span class="n">sigma_a</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Exponential</span><span class="p">(</span><span class="s1">&#39;sigma_a&#39;</span><span class="p">,</span> <span class="mf">1.</span><span class="p">)</span>
    
    <span class="c1"># Varying intercepts velocity model:</span>
    <span class="n">a</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Deterministic</span><span class="p">(</span><span class="s1">&#39;a&#39;</span><span class="p">,</span> <span class="n">g</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="n">g</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="n">u</span> <span class="o">+</span> <span class="n">g</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="o">*</span> <span class="n">avg_no_stim</span><span class="p">)</span>
    <span class="n">za_mouse</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="s1">&#39;za_mouse&#39;</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="mf">0.</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="mf">1.</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="n">n_mice</span><span class="p">)</span>
    <span class="n">a_mouse</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Deterministic</span><span class="p">(</span><span class="s1">&#39;a_mouse&#39;</span><span class="p">,</span> <span class="n">a</span> <span class="o">+</span> <span class="n">za_mouse</span> <span class="o">*</span> <span class="n">sigma_a</span><span class="p">)</span>
    <span class="c1"># Common slope:</span>
    <span class="n">b</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="s1">&#39;b&#39;</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="mf">0.</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="mf">1.</span><span class="p">)</span>
    
    <span class="n">mouse_idx</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">intX</span><span class="p">(</span><span class="n">pm</span><span class="o">.</span><span class="n">Data</span><span class="p">(</span><span class="s1">&#39;mouse_idx&#39;</span><span class="p">,</span> <span class="n">mouse</span><span class="p">))</span>
    <span class="n">no_stim_vals</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Data</span><span class="p">(</span><span class="s1">&#39;no_stim_vals&#39;</span><span class="p">,</span> <span class="n">no_stim</span><span class="p">)</span>
    <span class="c1"># Expected value per mouse:</span>
    <span class="n">theta</span> <span class="o">=</span> <span class="n">a_mouse</span><span class="p">[</span><span class="n">mouse_idx</span><span class="p">]</span> <span class="o">+</span> <span class="n">b</span> <span class="o">*</span> <span class="n">no_stim_vals</span>
    <span class="c1"># Model error:</span>
    <span class="n">sigma</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Exponential</span><span class="p">(</span><span class="s1">&#39;sigma&#39;</span><span class="p">,</span> <span class="mf">1.</span><span class="p">)</span>
    
    <span class="n">y</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="s1">&#39;y&#39;</span><span class="p">,</span> <span class="n">theta</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="n">sigma</span><span class="p">,</span> <span class="n">observed</span><span class="o">=</span><span class="n">log_firingrate</span><span class="p">)</span>
    <span class="n">pm</span><span class="o">.</span><span class="n">model_to_graphviz</span><span class="p">(</span><span class="n">contextual_effect</span><span class="p">)</span>    
    
    <span class="n">contextual_effect_trace</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="mi">1000</span><span class="p">,</span> <span class="n">tune</span><span class="o">=</span><span class="mi">8000</span><span class="p">,</span> <span class="n">target_accept</span><span class="o">=</span><span class="mf">0.99</span><span class="p">,</span> <span class="n">random_seed</span><span class="o">=</span><span class="n">RANDOM_SEED</span><span class="p">)</span>
<span class="n">az</span><span class="o">.</span><span class="n">summary</span><span class="p">(</span><span class="n">contextual_effect_trace</span><span class="p">,</span> <span class="n">var_names</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;g&quot;</span><span class="p">],</span> <span class="n">round_to</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Auto-assigning NUTS sampler...
Initializing NUTS using jitter+adapt_diag...
Multiprocess sampling (4 chains in 4 jobs)
NUTS: [sigma, b, za_mouse, sigma_a, g]
</pre></div>
</div>
<div class="output text_html">
<div>
    <style>
        /* Turns off some styling */
        progress {
            /* gets rid of default border in Firefox and Opera. */
            border: none;
            /* Needs to be in here for Safari polyfill so background images work as expected. */
            background-size: auto;
        }
        .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
            background: #F44336;
        }
    </style>
  <progress value='36000' class='' max='36000' style='width:300px; height:20px; vertical-align: middle;'></progress>
  100.00% [36000/36000 01:06<00:00 Sampling 4 chains, 0 divergences]
</div>
</div><div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Sampling 4 chains for 8_000 tune and 1_000 draw iterations (32_000 + 4_000 draws total) took 68 seconds.
The number of effective samples is smaller than 25% for some parameters.
</pre></div>
</div>
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>mean</th>
      <th>sd</th>
      <th>hdi_3%</th>
      <th>hdi_97%</th>
      <th>mcse_mean</th>
      <th>mcse_sd</th>
      <th>ess_mean</th>
      <th>ess_sd</th>
      <th>ess_bulk</th>
      <th>ess_tail</th>
      <th>r_hat</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>g[0]</th>
      <td>1.42</td>
      <td>0.05</td>
      <td>1.33</td>
      <td>1.52</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1659.49</td>
      <td>1652.00</td>
      <td>1663.20</td>
      <td>2439.39</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>g[1]</th>
      <td>0.70</td>
      <td>0.09</td>
      <td>0.54</td>
      <td>0.85</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>2506.83</td>
      <td>2506.83</td>
      <td>2533.21</td>
      <td>3031.95</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>g[2]</th>
      <td>0.39</td>
      <td>0.19</td>
      <td>0.04</td>
      <td>0.76</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1860.56</td>
      <td>1860.56</td>
      <td>1861.10</td>
      <td>2578.32</td>
      <td>1.0</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># HIDE CODE</span>

<span class="n">pm</span><span class="o">.</span><span class="n">model_to_graphviz</span><span class="p">(</span><span class="n">contextual_effect</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/multilevel_modeling_neurons_106_0.svg" src="../_images/multilevel_modeling_neurons_106_0.svg" /></div>
</div>
<p>So we might infer from this that mice with higher proportions of neurons without stims tend to have higher baseline levels of firingrate. This seems to be new, as up to this point we saw that <code class="docutils literal notranslate"><span class="pre">no_stim</span></code> was <em>negatively</em> associated with firingrate levels. But remember this was at the neuron-level: firingrate tends to be higher in neurons with stims. But at the mouse-level it seems that the less stims on average in the mouse, the more firingrate. So it’s not that contradictory. What’s more, the estimate for <span class="math notranslate nohighlight">\(\gamma_2\)</span> is quite uncertain and overlaps with zero, so it’s possible that the relationship is not that strong. And finally, let’s note that <span class="math notranslate nohighlight">\(\gamma_2\)</span> estimates something else than velocity’s effect, as this is already taken into account by <span class="math notranslate nohighlight">\(\gamma_1\)</span> – it answers the question “once we know velocity level in the mouse, is there any value in learning about the proportion of neurons without stims?”.</p>
<p>All of this is to say that we shouldn’t interpret this causally: there is no credible mecanism by which a stim (or absence thereof) <em>causes</em> firingrate emissions. More probably, our causal graph is missing something: a confounding variable, one that influences both stim construction and firingrate levels, is lurking somewhere in the dark… Perhaps is it the type of soil, which might influence what type of structures are built <em>and</em> the level of firingrate? Maybe adding this to our model would help with causal inference.</p>
</div>
<div class="section" id="prediction">
<h2>Prediction<a class="headerlink" href="#prediction" title="Permalink to this headline">¶</a></h2>
<p>Gelman (2006) used cross-validation tests to check the prediction error of the unpooled, pooled, and partially-pooled models</p>
<p><strong>root mean squared cross-validation prediction errors</strong>:</p>
<ul class="simple">
<li><p>unpooled = 0.86</p></li>
<li><p>pooled = 0.84</p></li>
<li><p>multilevel = 0.79</p></li>
</ul>
<p>There are two types of prediction that can be made in a multilevel model:</p>
<ol class="simple">
<li><p>a new individual within an <em>existing</em> group</p></li>
<li><p>a new individual within a <em>new</em> group</p></li>
</ol>
<p>The first type is the easiest one, as we’ve generally already sampled from the existing group. For this model, the first type of posterior prediction is the only one making sense, as mice are not added or deleted every day. So, if we wanted to make a prediction for, say, a new neuron with no stim in St. Louis mouse, we just need to sample from the firingrate model with the appropriate intercept:</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># HIDE CODE</span>

<span class="n">mouse_lookup</span><span class="p">[</span><span class="s2">&quot;ST LOUIS&quot;</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>69
</pre></div>
</div>
</div>
</div>
<p>That is,</p>
<div class="math notranslate nohighlight">
\[\tilde{y}_i \sim N(\alpha_{69} + \beta (x_i=1), \sigma_y^2)\]</div>
<p>Because we judiciously set the mouse index and no_stim values as shared variables earlier, we can modify them directly to the desired values (69 and 1 respectively) and sample corresponding posterior predictions, without having to redefine and recompile our model. Using the model just above:</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># HIDE CODE</span>

<span class="k">with</span> <span class="n">contextual_effect</span><span class="p">:</span>
    <span class="n">pm</span><span class="o">.</span><span class="n">set_data</span><span class="p">({</span>
        <span class="s2">&quot;mouse_idx&quot;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">69</span><span class="p">]),</span>
        <span class="s2">&quot;no_stim_vals&quot;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">])</span>
    <span class="p">})</span>
    <span class="n">stl_pred</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">sample_posterior_predictive</span><span class="p">(</span><span class="n">contextual_effect_trace</span><span class="p">,</span> <span class="n">random_seed</span><span class="o">=</span><span class="n">RANDOM_SEED</span><span class="p">)</span>
<span class="n">az</span><span class="o">.</span><span class="n">plot_posterior</span><span class="p">(</span><span class="n">stl_pred</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html">
<div>
    <style>
        /* Turns off some styling */
        progress {
            /* gets rid of default border in Firefox and Opera. */
            border: none;
            /* Needs to be in here for Safari polyfill so background images work as expected. */
            background-size: auto;
        }
        .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
            background: #F44336;
        }
    </style>
  <progress value='4000' class='' max='4000' style='width:300px; height:20px; vertical-align: middle;'></progress>
  100.00% [4000/4000 00:05<00:00]
</div>
</div><div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>/home/m/anaconda3/envs/tf/lib/python3.6/site-packages/arviz/data/base.py:146: UserWarning: More chains (4000) than draws (919). Passed array should have shape (chains, draws, *shape)
  UserWarning,
</pre></div>
</div>
<img alt="../_images/multilevel_modeling_neurons_111_2.png" src="../_images/multilevel_modeling_neurons_111_2.png" />
</div>
</div>
</div>
<div class="section" id="benefits-of-multilevel-models">
<h2>Benefits of Multilevel Models<a class="headerlink" href="#benefits-of-multilevel-models" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>Accounting for natural hierarchical structure of observational data.</p></li>
<li><p>Estimation of coefficients for (under-represented) groups.</p></li>
<li><p>Incorporating individual- and group-level information when estimating group-level coefficients.</p></li>
<li><p>Allowing for variation among individual-level coefficients across groups.</p></li>
</ul>
</div>
<div class="section" id="references">
<h2>References<a class="headerlink" href="#references" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>Gelman, A., &amp; Hill, J. (2006), <em>Data Analysis Using Regression and Multilevel/Hierarchical Models (1st ed.)</em>, Cambridge University Press.</p></li>
<li><p>Gelman, A. (2006), <em>Multilevel (Hierarchical) modeling: what it can and cannot do</em>, Technometrics, 48(3), 432–435.</p></li>
<li><p>McElreath, R. (2020), <em>Statistical Rethinking - A Bayesian Course with Examples in R and Stan (2nd ed.)</em>, CRC Press.</p></li>
</ul>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./motivation"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        
            <!-- Previous / next buttons -->
<div class='prev-next-area'> 
    <a class='left-prev' id="prev-link" href="multilevel_modeling_lfp.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">Multilevel modeling of LFP</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="../lfp_example/quick_lfp.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">LFP example</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
        
        </div>
    </div>
    <footer class="footer">
    <div class="container">
      <p>
        
          By Max Myroshnychenko<br/>
        
            &copy; Copyright 2021.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>
  
  <script src="../_static/js/index.be7d3bbb2ef33a8344ce.js"></script>

  </body>
</html>